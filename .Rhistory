alpha2 ~ dnorm(0, 5)
sigma ~ dunif(0, 10)
tau <- 1/sigma^2
# likelihood
for(i in 1:length(y)){
y_mu[i] <- exp(alpha1 + alpha2 * era[i])
y[i] ~ dlnorm(log(y_mu[i]), tau)
# Simulated data for posterior predictive checks
y.sim[i] ~ dlnorm(log(y_mu[i]), tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
#Bayesian P values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
zm = coda.samples(jm, variable.names = c("alpha1", "alpha2", "sigma", "p.sd",
"p.mean", "p.discrep"),
n.iter = n.iter, n.thin = 1)
zj = jags.samples(jm, variable.names = c("alpha1", "alpha2", "sigma",
"y.sim", "p.sd", "p.mean", "p.discrep"),
n.iter = n.iter, n.thin = 1)
traceplot(zm)
densplot(zm)
summary(zm)
gelman.diag(zm, multivariate = F)
zj$p.sd
zj$p.mean
zj$p.max
zj$p.discrep
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.sim), col="red")
lm1 <- lm(size1mm ~ era, data = dat)
summary(lm1)
exp(2.5)
exp(2.2)
data = list(
y = dat$size1mm,
era = dat$eraJ
)
inits = list(
list(
alpha1 = 15,
alpha2 = 0,
sigma = 5
),
list(
alpha1 = 5,
alpha2 = 0.7,
sigma = 1
)
)
n.adapt = 1000
n.update = 1000
n.iter = 1000
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
alpha1 ~ dnorm(15, 30)
alpha2 ~ dnorm(0, 2)
sigma ~ dunif(0, 5)
tau <- 1/sigma^2
# likelihood
for(i in 1:length(y)){
y_mu[i] <- exp(alpha1 + alpha2 * era[i])
y[i] ~ dlnorm(log(y_mu[i]), tau)
# Simulated data for posterior predictive checks
y.sim[i] ~ dlnorm(log(y_mu[i]), tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
#Bayesian P values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("alpha1", "alpha2", "sigma", "p.sd",
"p.mean", "p.discrep"),
n.iter = n.iter, n.thin = 1)
head(zm[[1]])
zj = jags.samples(jm, variable.names = c("alpha1", "alpha2", "sigma",
"y.sim", "p.sd", "p.mean", "p.discrep"),
n.iter = n.iter, n.thin = 1)
traceplot(zm)
plot(zm)
zm = coda.samples(jm, variable.names = c("alpha1", "alpha2", "sigma"),
n.iter = n.iter, n.thin = 1)
plot(zm)
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
alpha1 ~ dnorm(15, 30)
alpha2 ~ dnorm(0, 2)
sigma ~ dunif(0, 5)
tau <- 1/sigma^2
# likelihood
for(i in 1:length(y)){
y_mu[i] <- exp(alpha1 + alpha2 * era[i])
y[i] ~ dlnorm(log(y_mu[i] + 0.67*tau), tau)
# Simulated data for posterior predictive checks
y.sim[i] ~ dlnorm(log(y_mu[i] + 0.67*tau), tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
#Bayesian P values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("alpha1", "alpha2", "sigma"),
n.iter = n.iter, n.thin = 1)
head(zm[[1]])
zj = jags.samples(jm, variable.names = c("alpha1", "alpha2", "sigma",
"y.sim", "p.sd", "p.mean", "p.discrep"),
n.iter = n.iter, n.thin = 1)
plot(zm)
exp(2.25)
summary(zm)
exp(2.24)
inits = list(
list(
alpha1 = 15,
alpha2 = 0,
sigma = 40
),
list(
alpha1 = 5,
alpha2 = 0.7,
sigma = 20
)
)
n.adapt = 3000
n.update = 3000
n.iter = 3000
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
alpha1 ~ dnorm(15, 30)
alpha2 ~ dnorm(0, 5)
sigma ~ dunif(0, 50)
tau <- 1/sigma^2
# likelihood
for(i in 1:length(y)){
y_mu[i] <- exp(alpha1 + alpha2 * era[i])
y[i] ~ dnorm(y_mu[i], tau)
# Simulated data for posterior predictive checks
y.sim[i] ~ dnorm(y_mu[i], tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
#Bayesian P values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("alpha1", "alpha2", "sigma", "p.sd",
"p.mean", "p.discrep", "p.max"),
n.iter = n.iter, n.thin = 1)
head(zm[[1]])
zj = jags.samples(jm, variable.names = c("alpha1", "alpha2", "sigma",
"y.sim", "p.sd", "p.mean", "p.discrep", "p.max"),
n.iter = n.iter, n.thin = 1)
traceplot(zm)
densplot(zm)
summary(zm)
exp(2.43)
data = list(
y = dat$size1mm,
era = dat$eraJ
)
inits = list(
list(
alpha1 = 15,
alpha2 = 0,
sigma = 5
),
list(
alpha1 = 5,
alpha2 = 0.7,
sigma = 1
)
)
n.adapt = 1000
n.update = 1000
n.iter = 1000
## JAGS model
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
alpha1 ~ dnorm(15, 30)
alpha2 ~ dnorm(0, 2)
sigma ~ dunif(0, 5)
tau <- 1/sigma^2
# likelihood
for(i in 1:length(y)){
y_mu[i] <- exp(alpha1 + alpha2 * era[i])
y[i] ~ dlnorm(log(y_mu[i] - 0.67*tau), tau)
# Simulated data for posterior predictive checks
y.sim[i] ~ dlnorm(log(y_mu[i] - 0.67*tau), tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
#Bayesian P values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("alpha1", "alpha2", "sigma"),
n.iter = n.iter, n.thin = 1)
head(zm[[1]])
summary(zm)
exp(2.43)
dat <- childsDF
data = list(
y = dat$size1mm,
era = dat$eraJ
)
data = list(
y = dat$size1mm,
era = dat$eraJ
)
inits = list(
list(
alpha1 = 15,
alpha2 = 0,
sigma = 40
),
list(
alpha1 = 5,
alpha2 = 0.7,
sigma = 20
)
)
n.adapt = 1000
n.update = 1000
n.iter = 1000
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
alpha1 ~ dnorm(15, 30)
alpha2 ~ dnorm(0, 5)
sigma ~ dunif(0, 50)
tau <- 1/sigma^2
# likelihood
for(i in 1:length(y)){
y_mu[i] <- exp(alpha1 + alpha2 * era[i])
y[i] ~ dlnorm(log(y_mu[i]), tau)
# Simulated data for posterior predictive checks
y.sim[i] ~ dlnorm(log(y_mu[i]), tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
#Bayesian P values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("alpha1", "alpha2", "sigma", "p.sd",
"p.mean", "p.discrep"),
n.iter = n.iter, n.thin = 1)
summary(zm)
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.sim), col="red")
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
alpha1 ~ dnorm(15, 30)
alpha2 ~ dnorm(0, 5)
sigma ~ dunif(0, 50)
tau <- 1/sigma^2
# likelihood
for(i in 1:length(y)){
y_mu[i] <- exp(alpha1 + alpha2 * era[i])
y[i] ~ dlnorm(log(y_mu[i]) - 0.67*tau), tau)
# Simulated data for posterior predictive checks
y.sim[i] ~ dlnorm(log(y_mu[i]) - 0.67*tau), tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
#Bayesian P values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
alpha1 ~ dnorm(15, 30)
alpha2 ~ dnorm(0, 5)
sigma ~ dunif(0, 50)
tau <- 1/sigma^2
# likelihood
for(i in 1:length(y)){
y_mu[i] <- exp(alpha1 + alpha2 * era[i])
y[i] ~ dlnorm(log(y_mu[i] - 0.67*tau), tau)
# Simulated data for posterior predictive checks
y.sim[i] ~ dlnorm(log(y_mu[i] - 0.67*tau), tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
#Bayesian P values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
alpha1 ~ dnorm(15, 30)
alpha2 ~ dnorm(0, 5)
sigma ~ dunif(0, 50)
tau <- 1/sigma^2
# likelihood
for(i in 1:length(y)){
y_mu[i] <- exp(alpha1 + alpha2 * era[i])
y[i] ~ dlnorm(log(y_mu[i]) - 0.67*tau), tau)
# Simulated data for posterior predictive checks
y.sim[i] ~ dlnorm(log(y_mu[i]) - 0.67*tau), tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
#Bayesian P values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
alpha1 ~ dnorm(15, 30)
alpha2 ~ dnorm(0, 5)
sigma ~ dunif(0, 50)
tau <- 1/sigma^2
# likelihood
for(i in 1:length(y)){
y_mu[i] <- exp(alpha1 + alpha2 * era[i])
y[i] ~ dlnorm(log(y_mu[i]) - 0.67*tau, tau)
# Simulated data for posterior predictive checks
y.sim[i] ~ dlnorm(log(y_mu[i]) - 0.67*tau, tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
#Bayesian P values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("alpha1", "alpha2", "sigma", "p.sd",
"p.mean", "p.discrep"),
n.iter = n.iter, n.thin = 1)
head(zm[[1]])
traceplot(zm)
summary(zm)
## JAGS model
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
alpha1 ~ dnorm(15, 30)
alpha2 ~ dnorm(0, 5)
sigma ~ dunif(0, 50)
tau <- 1/sigma^2
# likelihood
for(i in 1:length(y)){
y_mu[i] <- exp(alpha1 + alpha2 * era[i])
y[i] ~ dlnorm(log(y_mu[i]), tau)
# Simulated data for posterior predictive checks
y.sim[i] ~ dlnorm(log(y_mu[i]), tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
#Bayesian P values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("alpha1", "alpha2", "sigma", "p.sd",
"p.mean", "p.discrep"),
n.iter = n.iter, n.thin = 1)
head(zm[[1]])
summary(zm)
exp(2.46)
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.sim), col="red")
