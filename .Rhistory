sjp.lmer(lmer1, type = "re", p.kr = F)
sjp.lmer(lmer1, type = "fe", p.kr = F)
##' Partially pooled model (with random slope and intercept for each group)
lmer2 <- lmer(size_log ~ x2z*x3z + (x2z | group_j), data = stat_dat)
summary(lmer2)
coef(lmer2)
sjp.lmer(lmer2, type = "re", p.kr = F)
sjp.lmer(lmer2, type = "fe", p.kr = F)
plot(lmer2)
## Prepare dataset for stats
stat_dat <- stat_dat %>%
mutate(x2z = scale_gelman(x2),
x3z = scale_gelman(x3),
group_j = as.integer(as.factor(sampleUnit)),
obs_id = seq(1:n()))
n_group_j = length(unique(stat_dat$group_j))
n_group_j
## Prepare dataset for stats
unique(stat_dat$sampleUnit)
unique(stat_dat$nest1)
unique(stat_dat$nest2)
unique(stat_dat$nest3)
unique(stat_dat$sampleArea)
unique(stat_dat$sample_area_tidal_ht)
unique(stat_dat$)
## Prepare dataset for stats
unique(stat_dat$sampleUnit)
stat_dat <- stat_dat %>%
mutate(x2z = scale_gelman(x2),
x3z = scale_gelman(x3),
group_j = as.integer(as.factor(sampleUnit)),
obs_id = seq(1:n()))
n_group_j = length(unique(stat_dat$group_j))
##' Pooled model
lm1 <- lm(size_log ~ x2z*x3z, data = stat_dat)
summary(lm1)
plot(lm1)
##' Partially pooled model (with random intercept for each group)
lmer1 <- lmer(size_log ~ x2z*x3z + (1 | group_j), data = stat_dat)
summary(lmer1)
sjp.lmer(lmer1, type = "re", p.kr = F)
sjp.lmer(lmer1, type = "fe", p.kr = F)
##' Partially pooled model (with random slope and intercept for each group)
lmer2 <- lmer(size_log ~ x2z*x3z + (x2z | group_j), data = stat_dat)
summary(lmer2)
plot(lmer1)
##' Partially pooled model (with random slope and intercept for each group)
lmer2 <- lmer(size_log ~ x2z*x3z + (x2z | group_j), data = stat_dat)
sjp.lmer(lmer1, type = "re", p.kr = F)
sjp.lmer(lmer1, type = "fe", p.kr = F)
summary(lm1)
CORES <- 4
SEED <- 101
## Pooled model
stan0 <- stan_lm(size_log ~ x2z*x3z, data = stat_dat,
prior = R2(0.5, what = "median"),
cores = CORES, seed = SEED)
plot(stan0)
plot(stan0, regex_pars = "x")
## Pooled model
stan0 <- stan_lm(size_log ~ x2z*x3z, data = stat_dat,
prior = R2(0.5, what = "median"),
cores = CORES, seed = SEED, adapt_delta = 0.99)
plot(stan0, regex_pars = "x")
## Group level intercepts
stan1 <- stan_lmer(size_log ~ x2z*x3z + (1 | group_j), data = stat_dat,
cores = CORES, seed = SEED, adapt_delta = 0.99)
plot(stan1, regex_pars = "x")
## Group level intercepts
stan1 <- stan_lmer(size_log ~ x2z*x3z + (1 | group_j), data = stat_dat,
cores = CORES, seed = SEED)
## Group level intercepts
stan1 <- stan_lmer(size_log ~ x2z*x3z + (1 | group_j), data = stat_dat,
cores = CORES, seed = SEED, adapt_delta = 0.99)
plot(stan1, regex_pars = "x")
get_stan_summary <- function(fit, y_label, prob_lwr = .05, prob_upr = .95){
## Extract posterior draws as dataframe
posterior_df <- as_data_frame(fit)
names(posterior_df)[1] <- "Intercept"
## Get median and 90% credible intervals
fit_summary <- posterior_df %>%
gather(key = parameter, value = estimate) %>%
group_by(parameter) %>%
summarise(median = median(estimate),
lower = quantile(estimate, probs = prob_lwr),
upper = quantile(estimate, probs = prob_upr)) %>%
mutate(y = y_label)
return(fit_summary)
}
fit_summary_like <- get_stan_summary(stan0, y_label = "LIKE")
fit_summary_like
## For re-scaling
# x_scaled <- (x - x_mu)/(2*x_sd)
# Get means and sd of continuous variables
x2_mu <- mean(stat_dat$x2)
x2_sd <- sd(stat_dat$x2)
x3_mu <- mean(stat_dat$x3)
x3_sd <- sd(stat_dat$x3)
## Create new data for plotting relationship
x2_rng <- range(stat_dat$x2)
x3_rng <- range(stat_dat$x3)
x2_steps <- seq(x2_rng[1], x2_rng[2], length.out = 80)
x3_steps <- seq(x3_rng[1], x3_rng[2], length.out = 80)
x2_steps
x3_steps
fit <- stan_1
fit <- stan1
stat_dat %>% count(x1)
fit
plot(fit)
## Hold nation at Italy (i.e., x1 = 1)
new_data_x2 <- expand.grid(x2 = 0, x3 = x3_steps)
## Hold nation at Italy (i.e., x1 = 1)
new_data_x3 <- expand.grid(x2 = 0, x3 = x3_steps)
## Combine
new_data <- rbind(new_data_x3) %>%
mutate(observation = seq_along(x2))
new_data
## Get posterior predictions
pred_lin <- posterior_linpred(fit, newdata = new_data)
## Hold nation at Italy (i.e., x1 = 1)
new_data_x3 <- expand.grid(x2z = 0, x3z = x3_steps)
## Combine
new_data <- rbind(new_data_x3) %>%
mutate(observation = seq_along(x2))
## Combine
new_data <- rbind(new_data_x3) %>%
mutate(observation = seq_along(x2z))
## Get posterior predictions
pred_lin <- posterior_linpred(fit, newdata = new_data)
newdat <- expand.grid(x2z = 0, x3z = x3_steps)
newdat
newdat$y_pred <- predict(lmer1, newdat, re.form = NA)
mm <- model.matrix(terms(lmer1), newdat)
newdat <- expand.grid(x2z = 0, x3z = x3_steps)
newdat$size_log <- predict(lmer1, newdat, re.form = NA)
mm <- model.matrix(terms(lmer1), newdat)
## or newdat$distance <- mm %*% fixef(fm1)
pvar1 <- diag(mm %*% tcrossprod(vcov(lmer1), mm))
tvar1 <- pvar1 + VarCorr(lmer1)$Subject[1] ## must be adapted for more complex models
tvar1 <- pvar1 + VarCorr(lmer1)$group_j[1] ## must be adapted for more complex models
tvar1
cmult <- 2 ## could use 1.96
## My data
stat_dat <- childsDF %>% filter(era == "present") %>%
mutate(y = size_log)
## My quantile for size threshold
my_quantile <- 0
## Choose data
stat_dat <- truncate_data(stat_dat, era = "combined", quant = my_quantile, filter_data = TRUE)
## My data
stat_dat <- childsDF %>% filter(era == "present") %>%
mutate(y = size_log)
## My quantile for size threshold
my_quantile <- 0
## Choose data
stat_dat <- truncate_data(stat_dat, era = "combined", quant = my_quantile, filter_data = TRUE)
stat_dat %>% count(sampleArea, era)
## Prepare dataset for stats
unique(stat_dat$sampleUnit)
stat_dat <- stat_dat %>%
mutate(x2z = scale_gelman(x2),
x3z = scale_gelman(x3),
group_j = as.integer(as.factor(sampleUnit)),
obs_id = seq(1:n()),
y = size_log)
n_group_j = length(unique(stat_dat$group_j))
##' Pooled model
lm1 <- lm(size_log ~ x2z*x3z, data = stat_dat)
summary(lm1)
plot(lm1)
##' Partially pooled model (with random intercept for each group)
lmer1 <- lmer(size_log ~ x2z*x3z + (1 | group_j), data = stat_dat)
summary(lmer1)
sjp.lmer(lmer1, type = "re", p.kr = F)
sjp.lmer(lmer1, type = "fe", p.kr = F)
stat_dat <- childsDF %>% filter(era == "present") %>%
mutate(y = size_log)
## My quantile for size threshold
my_quantile <- 0.25
## Choose data
stat_dat <- truncate_data(stat_dat, era = "combined", quant = my_quantile, filter_data = TRUE)
stat_dat %>% count(sampleArea, era)
##### PREP DATA FOR REGRESSION ANALYSIS #####
## To use a prior t distribution for alpha and beta (Gelman et al. 2008)
## Binary inputs are shifted to have a mean of 0 and to differ by 1 in their lower and upper conditions
## Other inputs are shifted to have a mean of 0 and scaled to have a sd of 0.5
## "This scaling puts continuous variables on the same scale as symmetric binary inputs (which, taking on the values of +- 0.5, have sd = 0.5)
## Prepare dataset for stats
unique(stat_dat$sampleUnit)
stat_dat <- stat_dat %>%
mutate(x2z = scale_gelman(x2),
x3z = scale_gelman(x3),
group_j = as.integer(as.factor(sampleUnit)),
obs_id = seq(1:n()),
y = size_log)
n_group_j = length(unique(stat_dat$group_j))
##### LMER #####
##' Pooled model
##' Partially pooled model (with random intercept for each group)
lmer1 <- lmer(size_log ~ x2z*x3z + (1 | group_j), data = stat_dat)
summary(lmer1)
sjp.lmer(lmer1, type = "re", p.kr = F)
sjp.lmer(lmer1, type = "fe", p.kr = F)
plot(lmer1)
## My quantile for size threshold
my_quantile <- 0.5
## Choose data
stat_dat <- truncate_data(stat_dat, era = "combined", quant = my_quantile, filter_data = TRUE)
stat_dat %>% count(sampleArea, era)
## Prepare dataset for stats
unique(stat_dat$sampleUnit)
stat_dat <- stat_dat %>%
mutate(x2z = scale_gelman(x2),
x3z = scale_gelman(x3),
group_j = as.integer(as.factor(sampleUnit)),
obs_id = seq(1:n()),
y = size_log)
n_group_j = length(unique(stat_dat$group_j))
##### LMER #####
##' Partially pooled model (with random intercept for each group)
lmer1 <- lmer(size_log ~ x2z*x3z + (1 | group_j), data = stat_dat)
summary(lmer1)
sjp.lmer(lmer1, type = "re", p.kr = F)
sjp.lmer(lmer1, type = "fe", p.kr = F)
plot(lmer1)
sjp.lmer(lmer1, type = "fe", p.kr = F)
newdat <- expand.grid(x2z = 0, x3z = x3_steps)
newdat$size_log <- predict(lmer1, newdat, re.form = NA)
mm <- model.matrix(terms(lmer1), newdat)
## or newdat$distance <- mm %*% fixef(fm1)
pvar1 <- diag(mm %*% tcrossprod(vcov(lmer1), mm))
tvar1 <- pvar1 + VarCorr(lmer1)$group_j[1] ## must be adapted for more complex models
##' Pooled model
lm1 <- lm(y ~ x2z*x3z, data = stat_dat)
##' Partially pooled model (with random intercept for each group)
lmer1 <- lmer(y ~ x2z*x3z + (1 | group_j), data = stat_dat)
summary(lmer1)
newdat <- expand.grid(x2z = 0, x3z = x3_steps)
newdat$y <- predict(lmer1, newdat, re.form = NA)
fit <- lmer1
newdat <- expand.grid(x2z = 0, x3z = x3_steps)
newdat$y <- predict(fit, newdat, re.form = NA)
mm <- model.matrix(terms(fit), newdat)
## or newdat$distance <- mm %*% fixef(fm1)
pvar1 <- diag(mm %*% tcrossprod(vcov(fit), mm))
tvar1 <- pvar1 + VarCorr(fit)$group_j[1] ## must be adapted for more complex models
cmult <- 2 ## could use 1.96
newdat <- data.frame(
newdat
, plo = newdat$y - cmult*sqrt(pvar1)
, phi = newdat$y + cmult*sqrt(pvar1)
, tlo = newdat$y - cmult*sqrt(tvar1)
, thi = newdat$y + cmult*sqrt(tvar1)
)
newdat
#plot confidence
g0 <- ggplot(newdat, aes(x = x3z, y = y)) + geom_point()
g0
x2z_rng <- range(stat_dat$x2z)
x3z_rng <- range(stat_dat$x3z)
x2z_steps <- seq(x2z_rng[1], x2z_rng[2], length.out = 80)
x3z_steps <- seq(x3z_rng[1], x3z_rng[2], length.out = 80)
newdat <- expand.grid(x2z = 0, x3z = x3z_steps)
newdat_x <- expand.grid(x2z = 0, x3z = x3_steps)
newdat_x
newdat$x3 <- newdat_x$x3z
newdat$y <- predict(fit, newdat, re.form = NA)
mm <- model.matrix(terms(fit), newdat)
## or newdat$distance <- mm %*% fixef(fm1)
pvar1 <- diag(mm %*% tcrossprod(vcov(fit), mm))
tvar1 <- pvar1 + VarCorr(fit)$group_j[1] ## must be adapted for more complex models
cmult <- 2 ## could use 1.96
newdat <- data.frame(
newdat
, plo = newdat$y - cmult*sqrt(pvar1)
, phi = newdat$y + cmult*sqrt(pvar1)
, tlo = newdat$y - cmult*sqrt(tvar1)
, thi = newdat$y + cmult*sqrt(tvar1)
)
#plot confidence
g0 <- ggplot(newdat, aes(x = x3z, y = y)) + geom_point()
g0
#plot confidence
g0 <- ggplot(newdat, aes(x = x3, y = y)) + geom_point()
g0
g0 + geom_pointrange(aes(ymin = plo, ymax = phi))+
labs(title="CI based on fixed-effects uncertainty ONLY")
stat_dat
g0 + geom_pointrange(aes(ymin = plo, ymax = phi))+
labs(title="CI based on fixed-effects uncertainty ONLY") +
geom_point(data = stat_dat, aes(tideHTm, size_log), color = "red")
#plot prediction
g0 + geom_pointrange(aes(ymin = tlo, ymax = thi))+
labs(title="CI based on FE uncertainty + RE variance") +
geom_point(data = stat_dat, aes(tideHTm, size_log), color = "red")
## My quantile for size threshold
my_quantile <- 0
## Choose data
stat_dat <- truncate_data(stat_dat, era = "combined", quant = my_quantile, filter_data = TRUE)
stat_dat %>% count(sampleArea, era)
##### PREP DATA FOR REGRESSION ANALYSIS #####
## To use a prior t distribution for alpha and beta (Gelman et al. 2008)
## Binary inputs are shifted to have a mean of 0 and to differ by 1 in their lower and upper conditions
## Other inputs are shifted to have a mean of 0 and scaled to have a sd of 0.5
## "This scaling puts continuous variables on the same scale as symmetric binary inputs (which, taking on the values of +- 0.5, have sd = 0.5)
## Prepare dataset for stats
unique(stat_dat$sampleUnit)
stat_dat <- stat_dat %>%
mutate(x2z = scale_gelman(x2),
x3z = scale_gelman(x3),
group_j = as.integer(as.factor(sampleUnit)),
obs_id = seq(1:n()),
y = size_log)
n_group_j = length(unique(stat_dat$group_j))
##### LMER #####
##' Pooled model
lm1 <- lm(y ~ x2z*x3z, data = stat_dat)
summary(lm1)
plot(lm1)
sjp.lmer(lmer1, type = "re", p.kr = F)
sjp.lmer(lmer1, type = "fe", p.kr = F)
plot(lmer1)
# x_scaled <- (x - x_mu)/(2*x_sd)
# Get means and sd of continuous variables
x2_mu <- mean(stat_dat$x2)
x2_sd <- sd(stat_dat$x2)
x3_mu <- mean(stat_dat$x3)
x3_sd <- sd(stat_dat$x3)
## Create new data for plotting relationship
x2_rng <- range(stat_dat$x2)
x3_rng <- range(stat_dat$x3)
x2z_rng <- range(stat_dat$x2z)
x3z_rng <- range(stat_dat$x3z)
x2_steps <- seq(x2_rng[1], x2_rng[2], length.out = 80)
x3_steps <- seq(x3_rng[1], x3_rng[2], length.out = 80)
x2z_steps <- seq(x2z_rng[1], x2z_rng[2], length.out = 80)
x3z_steps <- seq(x3z_rng[1], x3z_rng[2], length.out = 80)
##### LIKE - LMER predictions #####
fit <- lmer1
newdat <- expand.grid(x2z = 0, x3z = x3z_steps)
newdat_x <- expand.grid(x2z = 0, x3z = x3_steps)
newdat$x3 <- newdat_x$x3z
newdat$y <- predict(fit, newdat, re.form = NA)
mm <- model.matrix(terms(fit), newdat)
## or newdat$distance <- mm %*% fixef(fm1)
pvar1 <- diag(mm %*% tcrossprod(vcov(fit), mm))
tvar1 <- pvar1 + VarCorr(fit)$group_j[1] ## must be adapted for more complex models
cmult <- 2 ## could use 1.96
newdat <- data.frame(
newdat
, plo = newdat$y - cmult*sqrt(pvar1)
, phi = newdat$y + cmult*sqrt(pvar1)
, tlo = newdat$y - cmult*sqrt(tvar1)
, thi = newdat$y + cmult*sqrt(tvar1)
)
# plot confidence
g0 <- ggplot(newdat, aes(x = x3, y = y)) + geom_point()
g0
g0 + geom_pointrange(aes(ymin = plo, ymax = phi))+
labs(title="CI based on fixed-effects uncertainty ONLY") +
geom_point(data = stat_dat, aes(tideHTm, size_log), color = "red")
#plot prediction
g0 + geom_pointrange(aes(ymin = tlo, ymax = thi))+
labs(title="CI based on FE uncertainty + RE variance") +
geom_point(data = stat_dat, aes(tideHTm, size_log), color = "red")
## My data
stat_dat <- childsDF %>% filter(era == "present") %>%
mutate(y = size_log)
## My quantile for size threshold
my_quantile <- 0
## Choose data
stat_dat <- truncate_data(stat_dat, era = "combined", quant = my_quantile, filter_data = TRUE)
stat_dat %>% count(sampleArea, era)
##### PREP DATA FOR REGRESSION ANALYSIS #####
## To use a prior t distribution for alpha and beta (Gelman et al. 2008)
## Binary inputs are shifted to have a mean of 0 and to differ by 1 in their lower and upper conditions
## Other inputs are shifted to have a mean of 0 and scaled to have a sd of 0.5
## "This scaling puts continuous variables on the same scale as symmetric binary inputs (which, taking on the values of +- 0.5, have sd = 0.5)
## Prepare dataset for stats
unique(stat_dat$sampleUnit)
stat_dat <- stat_dat %>%
mutate(x2z = scale_gelman(x2),
x3z = scale_gelman(x3),
group_j = as.integer(as.factor(sampleUnit)),
obs_id = seq(1:n()),
y = size_log)
n_group_j = length(unique(stat_dat$group_j))
##### LMER #####
##' Pooled model
lm1 <- lm(y ~ x2z*x3z, data = stat_dat)
summary(lm1)
plot(lm1)
sjp.lmer(lmer1, type = "re", p.kr = F)
sjp.lmer(lmer1, type = "fe", p.kr = F)
plot(lmer1)
# x_scaled <- (x - x_mu)/(2*x_sd)
# Get means and sd of continuous variables
x2_mu <- mean(stat_dat$x2)
x2_sd <- sd(stat_dat$x2)
x3_mu <- mean(stat_dat$x3)
x3_sd <- sd(stat_dat$x3)
## Create new data for plotting relationship
x2_rng <- range(stat_dat$x2)
x3_rng <- range(stat_dat$x3)
x2z_rng <- range(stat_dat$x2z)
x3z_rng <- range(stat_dat$x3z)
x2_steps <- seq(x2_rng[1], x2_rng[2], length.out = 80)
x3_steps <- seq(x3_rng[1], x3_rng[2], length.out = 80)
x2z_steps <- seq(x2z_rng[1], x2z_rng[2], length.out = 80)
x3z_steps <- seq(x3z_rng[1], x3z_rng[2], length.out = 80)
##### LIKE - LMER predictions #####
fit <- lmer1
newdat <- expand.grid(x2z = 0, x3z = x3z_steps)
newdat_x <- expand.grid(x2z = 0, x3z = x3_steps)
newdat$x3 <- newdat_x$x3z
newdat$y <- predict(fit, newdat, re.form = NA)
mm <- model.matrix(terms(fit), newdat)
## or newdat$distance <- mm %*% fixef(fm1)
pvar1 <- diag(mm %*% tcrossprod(vcov(fit), mm))
tvar1 <- pvar1 + VarCorr(fit)$group_j[1] ## must be adapted for more complex models
cmult <- 2 ## could use 1.96
newdat <- data.frame(
newdat
, plo = newdat$y - cmult*sqrt(pvar1)
, phi = newdat$y + cmult*sqrt(pvar1)
, tlo = newdat$y - cmult*sqrt(tvar1)
, thi = newdat$y + cmult*sqrt(tvar1)
)
# plot confidence
g0 <- ggplot(newdat, aes(x = x3, y = y)) + geom_point()
g0
g0 + geom_pointrange(aes(ymin = plo, ymax = phi))+
labs(title="CI based on fixed-effects uncertainty ONLY") +
geom_point(data = stat_dat, aes(tideHTm, size_log), color = "red")
#plot prediction
g0 + geom_pointrange(aes(ymin = tlo, ymax = thi))+
labs(title="CI based on FE uncertainty + RE variance") +
geom_point(data = stat_dat, aes(tideHTm, size_log), color = "red")
## My data
stat_dat <- childsDF %>% filter(era == "present") %>%
mutate(y = size_log)
## My quantile for size threshold
my_quantile <- 0
## Choose data
stat_dat <- truncate_data(stat_dat, era = "combined", quant = my_quantile, filter_data = TRUE)
stat_dat %>% count(sampleArea, era)
## Prepare dataset for stats
unique(stat_dat$sampleUnit)
stat_dat <- stat_dat %>%
mutate(x2z = scale_gelman(x2),
x3z = scale_gelman(x3),
group_j = as.integer(as.factor(sampleUnit)),
obs_id = seq(1:n()),
y = size_log)
n_group_j = length(unique(stat_dat$group_j))
##### LMER #####
##' Pooled model
lm1 <- lm(y ~ x2z*x3z, data = stat_dat)
summary(lm1)
plot(lm1)
##' Partially pooled model (with random intercept for each group)
lmer1 <- lmer(y ~ x2z*x3z + (1 | group_j), data = stat_dat)
summary(lmer1)
sjp.lmer(lmer1, type = "re", p.kr = F)
sjp.lmer(lmer1, type = "fe", p.kr = F)
plot(lmer1)
## For re-scaling
# x_scaled <- (x - x_mu)/(2*x_sd)
# Get means and sd of continuous variables
x2_mu <- mean(stat_dat$x2)
x2_sd <- sd(stat_dat$x2)
x3_mu <- mean(stat_dat$x3)
x3_sd <- sd(stat_dat$x3)
## Create new data for plotting relationship
x2_rng <- range(stat_dat$x2)
x3_rng <- range(stat_dat$x3)
x2z_rng <- range(stat_dat$x2z)
x3z_rng <- range(stat_dat$x3z)
x2_steps <- seq(x2_rng[1], x2_rng[2], length.out = 80)
x3_steps <- seq(x3_rng[1], x3_rng[2], length.out = 80)
x2z_steps <- seq(x2z_rng[1], x2z_rng[2], length.out = 80)
x3z_steps <- seq(x3z_rng[1], x3z_rng[2], length.out = 80)
fit <- lmer1
newdat <- expand.grid(x2z = 0, x3z = x3z_steps)
newdat_x <- expand.grid(x2z = 0, x3z = x3_steps)
newdat$x3 <- newdat_x$x3z
newdat$y <- predict(fit, newdat, re.form = NA)
mm <- model.matrix(terms(fit), newdat)
## or newdat$distance <- mm %*% fixef(fm1)
pvar1 <- diag(mm %*% tcrossprod(vcov(fit), mm))
pvar1
VarCorr(fit)$group_j
VarCorr(fit)$group_j[1]
cmult <- 2 ## could use 1.96
newdat <- data.frame(
newdat
, plo = newdat$y - cmult*sqrt(pvar1)
, phi = newdat$y + cmult*sqrt(pvar1)
, tlo = newdat$y - cmult*sqrt(tvar1)
, thi = newdat$y + cmult*sqrt(tvar1)
)
# plot confidence
g0 <- ggplot(newdat, aes(x = x3, y = y)) + geom_point()
g0
g0 + geom_pointrange(aes(ymin = plo, ymax = phi))+
labs(title="CI based on fixed-effects uncertainty ONLY") +
geom_point(data = stat_dat, aes(tideHTm, size_log), color = "red")
#plot prediction
g0 + geom_pointrange(aes(ymin = tlo, ymax = thi))+
labs(title="CI based on FE uncertainty + RE variance") +
geom_point(data = stat_dat, aes(tideHTm, size_log), color = "red")
