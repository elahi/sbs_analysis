if(n_chains == 2){
inits = list(
list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = 2,
kappa = 1),
list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = -1,
kappa = -3)
)
}
## JAGS model
sink("sbs_bayes/models/pooled_lognormal_thc_JAGS.R")
cat("
model{
# priors
alpha ~ dnorm(0, 1/100^2)
beta ~ dnorm(0, 1/10^2)
sigma ~ dunif(0, 100)
tau <- 1/sigma^2
eta ~ dnorm(0, 1/10^2)
kappa ~ dnorm(0, 1/10^2)
# likelihood
for (i in 1:k){
mu[i] <- exp(alpha + beta*era[i] + eta*thc[i] + kappa*thc[i]*era[i])
y[i] ~ dlnorm(log(mu[i]), tau)
y.new[i] ~ dlnorm(log(mu[i]), tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.new[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.new <- sd(y.new)
p.sd <- step(sd.new - sd.data)
mean.data <- mean(y)
mean.new  <- mean(y.new)
p.mean <- step(mean.new - mean.data)
discrep.data <- sum(sq.error.data)
discrep.new <- sum(sq.error.new)
p.discrep <- step(discrep.new - discrep.data)
# Derived quantities
for(k in 1:length(thc_predict)){
y_pred[k] <- exp(alpha + beta*era + eta*thc_predict[k] + kappa*thc_predict[k]*era)
}
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooled_lognormal_thc_JAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
return(jm)
}
jm = pooled_model(dat = dat, iter_adapt = n.adapt, iter_update = n.update, n_chains = n_chains)
################################################################################
##' @title Pooled model - tidal height - lognormal distribution
##'
##' @author Robin Elahi
##' @contact elahi.robin@gmail.com
##'
##' @date 2017-09-04
##'
##' @log
################################################################################
# rm(list=ls(all=TRUE))
pooled_model <- function(dat, iter_adapt, iter_update, n_chains){
# load jags
library(rjags)
## Get data
data = list(
y = as.double(dat$size1mm),
k = as.double(length(dat$size1mm)),
thc = as.double(dat$thc),
era = as.double(dat$eraJ),
thc_predict = as.double(thc_predict)
)
## Iterations
n.adapt = iter_adapt
n.update = iter_update
## Inits
if(n_chains == 1){
inits = list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = 2,
kappa = 1)
}
if(n_chains == 2){
inits = list(
list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = 2,
kappa = 1),
list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = -1,
kappa = -3)
)
}
## JAGS model
sink("sbs_bayes/models/pooled_lognormal_thc_JAGS.R")
cat("
model{
# priors
alpha ~ dnorm(0, 1/100^2)
beta ~ dnorm(0, 1/10^2)
sigma ~ dunif(0, 100)
tau <- 1/sigma^2
eta ~ dnorm(0, 1/10^2)
kappa ~ dnorm(0, 1/10^2)
# likelihood
for (i in 1:k){
mu[i] <- exp(alpha + beta*era[i] + eta*thc[i] + kappa*thc[i]*era[i])
y[i] ~ dlnorm(log(mu[i]), tau)
y.new[i] ~ dlnorm(log(mu[i]), tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.new[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.new <- sd(y.new)
p.sd <- step(sd.new - sd.data)
mean.data <- mean(y)
mean.new  <- mean(y.new)
p.mean <- step(mean.new - mean.data)
discrep.data <- sum(sq.error.data)
discrep.new <- sum(sq.error.new)
p.discrep <- step(discrep.new - discrep.data)
# Derived quantities
for(k in 1:length(thc_predict)){
y_pred[k] <- alpha + beta*era + eta*thc_predict[k] + kappa*thc_predict[k]*era
}
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooled_lognormal_thc_JAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
return(jm)
}
jm = pooled_model(dat = dat, iter_adapt = n.adapt, iter_update = n.update, n_chains = n_chains)
thc_predict
################################################################################
##' @title Pooled model - tidal height - lognormal distribution
##'
##' @author Robin Elahi
##' @contact elahi.robin@gmail.com
##'
##' @date 2017-09-04
##'
##' @log
################################################################################
# rm(list=ls(all=TRUE))
pooled_model <- function(dat, iter_adapt, iter_update, n_chains){
# load jags
library(rjags)
## Get data
data = list(
y = as.double(dat$size1mm),
k = as.double(length(dat$size1mm)),
thc = as.double(dat$thc),
era = as.double(dat$eraJ),
thc_predict = as.double(thc_predict)
)
## Iterations
n.adapt = iter_adapt
n.update = iter_update
## Inits
if(n_chains == 1){
inits = list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = 2,
kappa = 1)
}
if(n_chains == 2){
inits = list(
list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = 2,
kappa = 1),
list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = -1,
kappa = -3)
)
}
## JAGS model
sink("sbs_bayes/models/pooled_lognormal_thc_JAGS.R")
cat("
model{
# priors
alpha ~ dnorm(0, 1/100^2)
beta ~ dnorm(0, 1/10^2)
sigma ~ dunif(0, 100)
tau <- 1/sigma^2
eta ~ dnorm(0, 1/10^2)
kappa ~ dnorm(0, 1/10^2)
# likelihood
for (i in 1:k){
mu[i] <- exp(alpha + beta*era[i] + eta*thc[i] + kappa*thc[i]*era[i])
y[i] ~ dlnorm(log(mu[i]), tau)
y.new[i] ~ dlnorm(log(mu[i]), tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.new[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.new <- sd(y.new)
p.sd <- step(sd.new - sd.data)
mean.data <- mean(y)
mean.new  <- mean(y.new)
p.mean <- step(mean.new - mean.data)
discrep.data <- sum(sq.error.data)
discrep.new <- sum(sq.error.new)
p.discrep <- step(discrep.new - discrep.data)
# Derived quantities
for(k in 1:length(thc_predict)){
y_pred[k] <- alpha + beta*era + eta*thc_predict[k] + kappa*thc_predict[k]*era
}
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooled_lognormal_thc_JAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
return(jm)
}
jm = pooled_model(dat = dat, iter_adapt = n.adapt, iter_update = n.update, n_chains = n_chains)
################################################################################
##' @title Pooled model - tidal height - lognormal distribution
##'
##' @author Robin Elahi
##' @contact elahi.robin@gmail.com
##'
##' @date 2017-09-04
##'
##' @log
################################################################################
# rm(list=ls(all=TRUE))
pooled_model <- function(dat, iter_adapt, iter_update, n_chains){
# load jags
library(rjags)
## Get data
data = list(
y = as.double(dat$size1mm),
k = as.double(length(dat$size1mm)),
thc = as.double(dat$thc),
era = as.double(dat$eraJ),
thc_predict = as.double(thc_predict)
)
## Iterations
n.adapt = iter_adapt
n.update = iter_update
## Inits
if(n_chains == 1){
inits = list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = 2,
kappa = 1)
}
if(n_chains == 2){
inits = list(
list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = 2,
kappa = 1),
list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = -1,
kappa = -3)
)
}
## JAGS model
sink("sbs_bayes/models/pooled_lognormal_thc_JAGS.R")
cat("
model{
# priors
alpha ~ dnorm(0, 1/100^2)
beta ~ dnorm(0, 1/10^2)
sigma ~ dunif(0, 100)
tau <- 1/sigma^2
eta ~ dnorm(0, 1/10^2)
kappa ~ dnorm(0, 1/10^2)
# likelihood
for (i in 1:k){
mu[i] <- exp(alpha + beta*era[i] + eta*thc[i] + kappa*thc[i]*era[i])
y[i] ~ dlnorm(log(mu[i]), tau)
y.new[i] ~ dlnorm(log(mu[i]), tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.new[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.new <- sd(y.new)
p.sd <- step(sd.new - sd.data)
mean.data <- mean(y)
mean.new  <- mean(y.new)
p.mean <- step(mean.new - mean.data)
discrep.data <- sum(sq.error.data)
discrep.new <- sum(sq.error.new)
p.discrep <- step(discrep.new - discrep.data)
# Derived quantities
for(k in 1:length(thc_predict)){
y_pred[k] <- alpha + beta*era + eta*thc_predict[k] #+ kappa*thc_predict[k]*era
}
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooled_lognormal_thc_JAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
return(jm)
}
source("sbs_bayes/model_pooled_lognormal_thc.R")
source("sbs_bayes/00_sbs_bayes_data.R")
source("sbs_bayes/model_pooled_lognormal_thc.R")
median_change <- function(dat){
dat_summary <- dat %>% group_by(era) %>%
summarise(size_median = median(size1mm, na.rm = TRUE))
test_stat <- 1 - (dat_summary$size_median[2]/dat_summary$size_median[1])
return(test_stat)
}
n.adapt <- 1000
n.update <- 1000
n.iter <- 1000
n_chains <- 2
dat <- hexDF
start_time <- proc.time()
jm = pooled_model(dat = dat, iter_adapt = n.adapt, iter_update = n.update, n_chains = n_chains)
################################################################################
##' @title Pooled model - tidal height - lognormal distribution
##'
##' @author Robin Elahi
##' @contact elahi.robin@gmail.com
##'
##' @date 2017-09-04
##'
##' @log
################################################################################
# rm(list=ls(all=TRUE))
pooled_model_thc <- function(dat, iter_adapt, iter_update, n_chains){
# load jags
library(rjags)
## Get data
data = list(
y = as.double(dat$size1mm),
k = as.double(length(dat$size1mm)),
thc = as.double(dat$thc),
era = as.double(dat$eraJ),
thc_predict = as.double(thc_predict)
)
## Iterations
n.adapt = iter_adapt
n.update = iter_update
## Inits
if(n_chains == 1){
inits = list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = 2,
kappa = 1)
}
if(n_chains == 2){
inits = list(
list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = 2,
kappa = 1),
list(
alpha = runif(1, 0, 30),
beta = runif(1, -10, 10),
sigma = 1,
eta = -1,
kappa = -3)
)
}
## JAGS model
sink("sbs_bayes/models/pooled_lognormal_thc_JAGS.R")
cat("
model{
# priors
alpha ~ dnorm(0, 1/100^2)
beta ~ dnorm(0, 1/10^2)
sigma ~ dunif(0, 100)
tau <- 1/sigma^2
eta ~ dnorm(0, 1/10^2)
kappa ~ dnorm(0, 1/10^2)
# likelihood
for (i in 1:k){
mu[i] <- exp(alpha + beta*era[i] + eta*thc[i] + kappa*thc[i]*era[i])
y[i] ~ dlnorm(log(mu[i]), tau)
y.new[i] ~ dlnorm(log(mu[i]), tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.new[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.new <- sd(y.new)
p.sd <- step(sd.new - sd.data)
mean.data <- mean(y)
mean.new  <- mean(y.new)
p.mean <- step(mean.new - mean.data)
discrep.data <- sum(sq.error.data)
discrep.new <- sum(sq.error.new)
p.discrep <- step(discrep.new - discrep.data)
# Derived quantities
for(k in 1:length(thc_predict)){
y_pred[k] <- alpha + beta*era + eta*thc_predict[k] #+ kappa*thc_predict[k]*era
}
}
", fill = TRUE)
sink()
jm = jags.model("sbs_bayes/models/pooled_lognormal_thc_JAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
return(jm)
}
jm = pooled_model_thc(dat = dat, iter_adapt = n.adapt, iter_update = n.update, n_chains = n_chains)
thc_predict
source("sbs_bayes/00_sbs_bayes_data.R")
source("sbs_bayes/model_pooled_lognormal_thc.R")
median_change <- function(dat){
dat_summary <- dat %>% group_by(era) %>%
summarise(size_median = median(size1mm, na.rm = TRUE))
test_stat <- 1 - (dat_summary$size_median[2]/dat_summary$size_median[1])
return(test_stat)
}
n.adapt <- 1000
n.update <- 1000
n.iter <- 1000
n_chains <- 2
dat <- hexDF
start_time <- proc.time()
jm = pooled_model_thc(dat = dat, iter_adapt = n.adapt, iter_update = n.update, n_chains = n_chains)
zm = coda.samples(jm, variable.names = c("alpha", "beta", "sigma", "eta", "kappa"),
n.iter = n.iter, n.thin = 1)
zj = jags.samples(jm, variable.names = c("alpha", "beta", "sigma", "eta", "kappa",
"y.new", "p.mean", "p.sd", "p.discrep"),
n.iter = n.iter, n.thin = 1)
end_time <- proc.time()
end_time - start_time
summary(zm)
exp(summary(zm)$stat[1]) # size intercept (past)
summary(zm)$stat[2]
dat %>% group_by(era) %>% summarise(median(size1mm))
median_change(dat)
plot(zm)
gelman.diag(zm, multivariate = F)
mean(zj$p.mean)
mean(zj$p.sd)
mean(zj$p.discrep)
hist(dat$size1mm, breaks = 20, freq=FALSE)
lines(density(zj$y.new), col="red")
coda_summary <- summary(zm)
hex_coda_quantile <- data.frame(coda_summary$quantile) %>%
mutate(sp = "LODI",
param = rownames(coda_summary$quantile))
dat <- childsDF
start_time <- proc.time()
jm = pooled_model(dat = dat, iter_adapt = n.adapt, iter_update = n.update, n_chains = n_chains)
zm = coda.samples(jm, variable.names = c("alpha", "beta", "sigma", "eta", "kappa"),
n.iter = n.iter, n.thin = 1)
zj = jags.samples(jm, variable.names = c("alpha", "beta", "sigma", "eta", "kappa",
"y.new", "p.mean", "p.sd", "p.discrep"),
n.iter = n.iter, n.thin = 1)
end_time <- proc.time()
end_time - start_time
#Produce a summary table for the parameters.
summary(zm)
dat <- childsDF
jm = pooled_model_thc(dat = dat, iter_adapt = n.adapt, iter_update = n.update, n_chains = n_chains)
zm = coda.samples(jm, variable.names = c("alpha", "beta", "sigma", "eta", "kappa"),
n.iter = n.iter, n.thin = 1)
zj = jags.samples(jm, variable.names = c("alpha", "beta", "sigma", "eta", "kappa",
"y.new", "p.mean", "p.sd", "p.discrep"),
n.iter = n.iter, n.thin = 1)
summary(zm)
exp(summary(zm)$stat[1]) # size intercept (past)
summary(zm)$stat[2]
dat %>% group_by(era) %>% summarise(median(size1mm))
median_change(dat)
plot(zm)
gelman.diag(zm, multivariate = F)
mean(zj$p.mean)
mean(zj$p.sd)
mean(zj$p.discrep)
hist(dat$size1mm, breaks = 20, freq=FALSE)
lines(density(zj$y.new), col="red")
