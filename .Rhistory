params <- rownames(coda_quantile)
summary_name <- paste("quantile", my_p, sep = "_")
coda_quantile <- coda_quantile %>%
mutate(coda_quantile = summary_name,
param = params)
# # Make prediction dataframe
# # Credible intervals
# y_predict <- summary(zj$y_pred, quantile, c(0.025, 0.5, 0.975))$stat
# pred_df$y_median <- y_predict[2, ]
# pred_df$y_lower <- y_predict[1, ]
# pred_df$y_upper <- y_predict[3, ]
#
# # Prediction intervals
# y_new <- summary(zj$y_new, quantile, c(0.025, 0.5, 0.975))$stat
# pred_df$y_median_pred <- y_new[2, ]
# pred_df$y_lower_pred <- y_new[1, ]
# pred_df$y_upper_pred <- y_new[3, ]
# pred_df$era <- ifelse(pred_df$era_predict == 0, "past", "present")
# Create list of all desired objects
coda_list.i <- list(coda_quantile, gd, pvals) #, pred_df)
coda_list[[i]] <- coda_list.i
}
return(coda_list)
}
## Choose the folder to output diagnostic plots
output_location = "3_analyse_data/bayes_output/logsize_density_tide/"
source("3_analyse_data/01_sbs_bayes_data.R")
source("R/truncate_data.R")
source("3_analyse_data/bayes_R/bayes_functions_general.R")
library(broom)
library(ggplot2)
library(cowplot)
##### SET UP JAGS MODEL #####
# load jags
library(rjags)
## Iterations (5000 may not be enough for Wara)
n.adapt = 1000
n.update = 1000
n.iter = 1000
p_vector = c(0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5)
inits <- list(
list(b = c(mean(log(y)), rep(0, p-1))),
list(b = c(0.2, rnorm(n = p-1, 0, 0.1))))
inits
# JAGS model
sink("3_analyse_data/bayes_models/modelJags.R")
cat("
model{
# priors
for(i in 1:p) {
b[i] ~ dnorm(0, 0.01)
}
sigma ~ dunif(0, 5)
tau <- 1/sigma^2
# likelihood
z <- X %*% b
for (i in 1:N){
mu[i] <- z[i]
y[i] ~ dnorm(mu[i], tau)
y.new[i] ~ dnorm(mu[i], tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.new[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.new <- sd(y.new)
p.sd <- step(sd.new - sd.data)
mean.data <- mean(y)
mean.new  <- mean(y.new)
p.mean <- step(mean.new - mean.data)
discrep.data <- sum(sq.error.data)
discrep.new <- sum(sq.error.new)
p.discrep <- step(discrep.new - discrep.data)
}
", fill = TRUE)
sink()
## Choose the model
my_model = "modelJags.R"
## Choose the folder to output diagnostic plots
output_location = "3_analyse_data/bayes_output/logsize_density_tide/"
##### LODI #####
my_sp <- "LODI"
# Run models and save diagnostic plots
coda_list <- loop_coda_list(hexDF, species_abbrev = my_sp, my_model = my_model,
figs_location = output_location)
loop_coda_list <- function(dat, species_abbrev, my_model, figs_location,
predictedName = "size_log",
predictorNames = c("era01", "density_m2", "tideHTm"),
my_formula = ~ zx[,1] * zx[,2] + zx[,1] * zx[,3]){
coda_list <- list()
for(i in 1:length(p_vector)){
my_p = p_vector[i]
## Truncate data
dat <- truncate_data(dat, quant = my_p)
# Standardize predictors
dat <- dat %>% mutate(era01 = ifelse(era == "past", 0, 1))
nData <- nrow(dat)
y <- as.matrix(dat[, predictedName])
x <- as.matrix(dat[, predictorNames])
# Get inits
inits <- list(
list(b = c(mean(log(y)), rep(0, p-1))),
list(b = c(0.2, rnorm(n = p-1, 0, 0.1))))
# Standardize
zx <- apply(x, MARGIN = 2, FUN = scale)
my_col_names <- colnames(zx)
# Get model matrix
X <- model.matrix(my_formula)
p <- dim(X)[2]
# Data for JAGS
data = list(
X = X,
y = as.double(as.vector(y)),
N = nData,
p = p
)
# # Center and standardize
# dens_mu <- mean(dat$density_m2)
# dens_sd <- sd(dat$density_m2)
# dens_cent <- dat$density_m2 - dens_mu
# dat$dens_stand <- dens_cent/dens_sd
#
# # For plotting predicted values of continuous variables
# my_prediction_length = 100
# pred_mat <- matrix(nrow = my_prediction_length, ncol = length(my_col_names))
# for(j in 2:length(my_col_names)){
#   my_minZ <- min(zx[,j])
#   my_maxZ <- max(zx[,j])
#   my_vectorZ <- seq(my_minZ, my_maxZ, length.out = 100)
#   pred_mat[, j] <- my_vectorZ
# }
# colnames(pred_mat) <- my_col_names
#
# # For prediction
# era_predict <- c(0,1)
# pred_df2 <- expand.grid(era_predict, pred_mat[, 2]) %>% tbl_df()
# colnames(pred_df2)[2] <- my_col_names[2]
#
# pred_df3 <- expand.grid(era_predict, pred_mat[, 3]) %>% tbl_df()
# colnames(pred_df3)[2] <- my_col_names[3]
jm = jags.model(paste("3_analyse_data/bayes_models/", my_model, sep = ""),
data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("b","sigma"),
n.iter = n.iter, n.thin = 2)
zj = jags.samples(jm, variable.names = c("b", "p.sd", "p.mean", "p.discrep", "y.new"),
n.iter = n.iter, n.thin = 2)
# Save trace plots
png(filename = paste(figs_location, "traceplot", species_abbrev, my_p, ".png", sep = "_"),
height = 9, width = 7, units = "in", res = 150)
par(mfrow = c(4,2))
traceplot(zm)
dev.off()
# Save density plots
png(filename = paste(figs_location, "densplot", species_abbrev, my_p, ".png", sep = "_"),
height = 9, width = 7, units = "in", res = 150)
par(mfrow = c(4,2))
densplot(zm)
dev.off()
# Model fit - compare observed vs simulated
png(filename = paste(figs_location, "model_fit", species_abbrev, my_p, ".png", sep = "_"),
height = 5, width = 5, units = "in", res = 150)
hist(dat$size_log, breaks = 15, freq=FALSE)
lines(density(zj$y.new), col="red")
dev.off()
# Test for convergence using the Gelman diagnostic.
gd <- gelman.diag(zm, multivariate = F)[[1]]
# Check Bayesian pvals
pvals <- c(p.mean = mean(zj$p.mean), p.sd = mean(zj$p.sd), p.discrep = mean(zj$p.discrep))
# # Get proportional change
# zj_b0 <- zj$beta0
# zj_b1 <- zj$beta1
# past_size <- 10^zj_b0
# present_size <- 10^(zj_b0 + zj_b1)
# prop_change <- (present_size - past_size)/past_size
# prop_change_quantile <- t(summary(prop_change, quantile, c(0.025, 0.25, 0.5, 0.75, 0.975))$stat)
# rownames(prop_change_quantile) <- "prop_change"
#
# Save coda summary
coda_summary <- summary(zm)
coda_quantile <- data.frame(coda_summary$quantile)
#coda_quantile <- rbind(coda_quantile, prop_change_quantile)
params <- rownames(coda_quantile)
summary_name <- paste("quantile", my_p, sep = "_")
coda_quantile <- coda_quantile %>%
mutate(coda_quantile = summary_name,
param = params)
# # Make prediction dataframe
# # Credible intervals
# y_predict <- summary(zj$y_pred, quantile, c(0.025, 0.5, 0.975))$stat
# pred_df$y_median <- y_predict[2, ]
# pred_df$y_lower <- y_predict[1, ]
# pred_df$y_upper <- y_predict[3, ]
#
# # Prediction intervals
# y_new <- summary(zj$y_new, quantile, c(0.025, 0.5, 0.975))$stat
# pred_df$y_median_pred <- y_new[2, ]
# pred_df$y_lower_pred <- y_new[1, ]
# pred_df$y_upper_pred <- y_new[3, ]
# pred_df$era <- ifelse(pred_df$era_predict == 0, "past", "present")
# Create list of all desired objects
coda_list.i <- list(coda_quantile, gd, pvals) #, pred_df)
coda_list[[i]] <- coda_list.i
}
return(coda_list)
}
# Run models and save diagnostic plots
coda_list <- loop_coda_list(hexDF, species_abbrev = my_sp, my_model = my_model,
figs_location = output_location)
loop_coda_list <- function(dat, species_abbrev, my_model, figs_location,
predictedName = "size_log",
predictorNames = c("era01", "density_m2", "tideHTm"),
my_formula = ~ zx[,1] * zx[,2] + zx[,1] * zx[,3]){
coda_list <- list()
for(i in 1:length(p_vector)){
my_p = p_vector[i]
## Truncate data
dat <- truncate_data(dat, quant = my_p)
# Standardize predictors
dat <- dat %>% mutate(era01 = ifelse(era == "past", 0, 1))
nData <- nrow(dat)
y <- as.matrix(dat[, predictedName])
x <- as.matrix(dat[, predictorNames])
# Standardize
zx <- apply(x, MARGIN = 2, FUN = scale)
my_col_names <- colnames(zx)
# Get model matrix
X <- model.matrix(my_formula)
p <- dim(X)[2]
# Get inits
inits <- list(
list(b = c(mean(log(y)), rep(0, p-1))),
list(b = c(0.2, rnorm(n = p-1, 0, 0.1))))
# Data for JAGS
data = list(
X = X,
y = as.double(as.vector(y)),
N = nData,
p = p
)
# # Center and standardize
# dens_mu <- mean(dat$density_m2)
# dens_sd <- sd(dat$density_m2)
# dens_cent <- dat$density_m2 - dens_mu
# dat$dens_stand <- dens_cent/dens_sd
#
# # For plotting predicted values of continuous variables
# my_prediction_length = 100
# pred_mat <- matrix(nrow = my_prediction_length, ncol = length(my_col_names))
# for(j in 2:length(my_col_names)){
#   my_minZ <- min(zx[,j])
#   my_maxZ <- max(zx[,j])
#   my_vectorZ <- seq(my_minZ, my_maxZ, length.out = 100)
#   pred_mat[, j] <- my_vectorZ
# }
# colnames(pred_mat) <- my_col_names
#
# # For prediction
# era_predict <- c(0,1)
# pred_df2 <- expand.grid(era_predict, pred_mat[, 2]) %>% tbl_df()
# colnames(pred_df2)[2] <- my_col_names[2]
#
# pred_df3 <- expand.grid(era_predict, pred_mat[, 3]) %>% tbl_df()
# colnames(pred_df3)[2] <- my_col_names[3]
jm = jags.model(paste("3_analyse_data/bayes_models/", my_model, sep = ""),
data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("b","sigma"),
n.iter = n.iter, n.thin = 2)
zj = jags.samples(jm, variable.names = c("b", "p.sd", "p.mean", "p.discrep", "y.new"),
n.iter = n.iter, n.thin = 2)
# Save trace plots
png(filename = paste(figs_location, "traceplot", species_abbrev, my_p, ".png", sep = "_"),
height = 9, width = 7, units = "in", res = 150)
par(mfrow = c(4,2))
traceplot(zm)
dev.off()
# Save density plots
png(filename = paste(figs_location, "densplot", species_abbrev, my_p, ".png", sep = "_"),
height = 9, width = 7, units = "in", res = 150)
par(mfrow = c(4,2))
densplot(zm)
dev.off()
# Model fit - compare observed vs simulated
png(filename = paste(figs_location, "model_fit", species_abbrev, my_p, ".png", sep = "_"),
height = 5, width = 5, units = "in", res = 150)
hist(dat$size_log, breaks = 15, freq=FALSE)
lines(density(zj$y.new), col="red")
dev.off()
# Test for convergence using the Gelman diagnostic.
gd <- gelman.diag(zm, multivariate = F)[[1]]
# Check Bayesian pvals
pvals <- c(p.mean = mean(zj$p.mean), p.sd = mean(zj$p.sd), p.discrep = mean(zj$p.discrep))
# # Get proportional change
# zj_b0 <- zj$beta0
# zj_b1 <- zj$beta1
# past_size <- 10^zj_b0
# present_size <- 10^(zj_b0 + zj_b1)
# prop_change <- (present_size - past_size)/past_size
# prop_change_quantile <- t(summary(prop_change, quantile, c(0.025, 0.25, 0.5, 0.75, 0.975))$stat)
# rownames(prop_change_quantile) <- "prop_change"
#
# Save coda summary
coda_summary <- summary(zm)
coda_quantile <- data.frame(coda_summary$quantile)
#coda_quantile <- rbind(coda_quantile, prop_change_quantile)
params <- rownames(coda_quantile)
summary_name <- paste("quantile", my_p, sep = "_")
coda_quantile <- coda_quantile %>%
mutate(coda_quantile = summary_name,
param = params)
# # Make prediction dataframe
# # Credible intervals
# y_predict <- summary(zj$y_pred, quantile, c(0.025, 0.5, 0.975))$stat
# pred_df$y_median <- y_predict[2, ]
# pred_df$y_lower <- y_predict[1, ]
# pred_df$y_upper <- y_predict[3, ]
#
# # Prediction intervals
# y_new <- summary(zj$y_new, quantile, c(0.025, 0.5, 0.975))$stat
# pred_df$y_median_pred <- y_new[2, ]
# pred_df$y_lower_pred <- y_new[1, ]
# pred_df$y_upper_pred <- y_new[3, ]
# pred_df$era <- ifelse(pred_df$era_predict == 0, "past", "present")
# Create list of all desired objects
coda_list.i <- list(coda_quantile, gd, pvals) #, pred_df)
coda_list[[i]] <- coda_list.i
}
return(coda_list)
}
# Run models and save diagnostic plots
coda_list <- loop_coda_list(hexDF, species_abbrev = my_sp, my_model = my_model,
figs_location = output_location)
# Create and rename diagnostic summary
gelman_df_hex <- loop_gelman_df(coda_list, species_abbrev = my_sp)
gelman_df_hex
# Create and rename pvalue summary
pval_df_hex <- loop_pval_df(coda_list, species_abbrev = my_sp)
pval_df_hex
# Create and rename coda summary
coda_df_hex <- loop_coda_df(coda_list, species_abbrev = my_sp)
coda_df_hex
coda_df_hex %>%
filter(!param %in% c("sigma", "b[1]")) %>%
ggplot(aes(param, X50.)) +
geom_errorbar(aes(ymin = X2.5., ymax = X97.5.)) +
geom_point() +
coord_flip() +
geom_hline(yintercept = 0, color = "gray", linetype = "dashed") +
labs(x = "Parameter",
y = "Standardized estimate")
coda_df_hex %>%
filter(!param %in% c("sigma", "b[1]")) %>%
ggplot(aes(param, X50., color = p_vector)) +
geom_errorbar(aes(ymin = X2.5., ymax = X97.5.)) +
geom_point() +
coord_flip() +
geom_hline(yintercept = 0, color = "gray", linetype = "dashed") +
labs(x = "Parameter",
y = "Standardized estimate")
coda_df_hex %>%
filter(!param %in% c("sigma", "b[1]")) %>%
ggplot(aes(param, X50.)) +
geom_errorbar(aes(ymin = X2.5., ymax = X97.5.)) +
geom_point() +
coord_flip() +
geom_hline(yintercept = 0, color = "gray", linetype = "dashed") +
labs(x = "Parameter",
y = "Standardized estimate") +
facet_wrap(~ p_vector)
coda_df_hex
coda_df_hex %>%
filter(!param %in% c("sigma", "b[1]")) %>%
ggplot(aes(param, X50.)) +
geom_errorbar(aes(ymin = X2.5., ymax = X97.5.)) +
geom_point() +
coord_flip() +
geom_hline(yintercept = 0, color = "gray", linetype = "dashed") +
labs(x = "Parameter",
y = "Standardized estimate") +
facet_wrap(~ quant)
loop_coda_list
ggsave("3_analyse_data/bayes_figs/caterpillar1.pdf")
# Run models and save diagnostic plots
coda_list <- loop_coda_list(hexDF, species_abbrev = my_sp, my_model = my_model,
figs_location = output_location,
my_formula = ~ zx[,1] + zx[,2] + zx[,1] + zx[,3])
# Create and rename diagnostic summary
gelman_df_hex <- loop_gelman_df(coda_list, species_abbrev = my_sp)
# Create and rename pvalue summary
pval_df_hex <- loop_pval_df(coda_list, species_abbrev = my_sp)
# Create and rename coda summary
coda_df_hex <- loop_coda_df(coda_list, species_abbrev = my_sp)
# Create and rename prediction dataframe
#pred_df_hex <- loop_pred_df(coda_list, species_abbrev = my_sp)
##### FIGURES #####
coda_df_hex %>%
filter(!param %in% c("sigma", "b[1]")) %>%
ggplot(aes(param, X50.)) +
geom_errorbar(aes(ymin = X2.5., ymax = X97.5.)) +
geom_point() +
coord_flip() +
geom_hline(yintercept = 0, color = "gray", linetype = "dashed") +
labs(x = "Parameter",
y = "Standardized estimate") +
facet_wrap(~ quant)
ggsave("3_analyse_data/bayes_figs/caterpillar1.pdf")
my_formula = ~ zx[,1] * zx[,2] + zx[,1] * zx[,3]
# Run models and save diagnostic plots
coda_list <- loop_coda_list(hexDF, species_abbrev = my_sp, my_model = my_model,
figs_location = output_location,
my_formula = ~ zx[,1] + zx[,2] + zx[,3])
my_formula = ~ zx[,1] + zx[,2] + zx[,3]
my_formula
my_p = p_vector[i]
i = 1
my_sp = "LIKE"
species_abbrev = my_sp
dat = childsDF
i = 1
my_model = "modelJags.R"
figs_location = "3_analyse_data/bayes_output/logsize_density_tide/"
my_p = p_vector[i]
## Truncate data
dat <- truncate_data(dat, quant = my_p)
# Standardize predictors
dat <- dat %>% mutate(era01 = ifelse(era == "past", 0, 1))
nData <- nrow(dat)
y <- as.matrix(dat[, predictedName])
predictedName = "size_log"
predictorNames = c("era01", "density_m2", "tideHTm")
y <- as.matrix(dat[, predictedName])
x <- as.matrix(dat[, predictorNames])
# Standardize
zx <- apply(x, MARGIN = 2, FUN = scale)
my_col_names <- colnames(zx)
# Get model matrix
X <- model.matrix(my_formula)
p <- dim(X)[2]
# Get inits
inits <- list(
list(b = c(mean(log(y)), rep(0, p-1))),
list(b = c(0.2, rnorm(n = p-1, 0, 0.1))))
# Data for JAGS
data = list(
X = X,
y = as.double(as.vector(y)),
N = nData,
p = p
)
jm = jags.model(paste("3_analyse_data/bayes_models/", my_model, sep = ""),
data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
source("3_analyse_data/01_sbs_bayes_data.R")
source("R/truncate_data.R")
source("3_analyse_data/bayes_R/bayes_functions_general.R")
library(broom)
library(ggplot2)
library(cowplot)
##### SET UP JAGS MODEL #####
# load jags
library(rjags)
## Iterations (5000 may not be enough for Wara)
n.adapt = 1000
n.update = 1000
n.iter = 1000
p_vector = c(0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5)
# JAGS model
sink("3_analyse_data/bayes_models/modelJags.R")
cat("
model{
# priors
for(i in 1:p) {
b[i] ~ dnorm(0, 0.01)
}
sigma ~ dunif(0, 5)
tau <- 1/sigma^2
# likelihood
z <- X %*% b
for (i in 1:N){
mu[i] <- z[i]
y[i] ~ dnorm(mu[i], tau)
y.new[i] ~ dnorm(mu[i], tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.new[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.new <- sd(y.new)
p.sd <- step(sd.new - sd.data)
mean.data <- mean(y)
mean.new  <- mean(y.new)
p.mean <- step(mean.new - mean.data)
discrep.data <- sum(sq.error.data)
discrep.new <- sum(sq.error.new)
p.discrep <- step(discrep.new - discrep.data)
}
", fill = TRUE)
sink()
## Choose the model
my_model = "modelJags.R"
## Choose the folder to output diagnostic plots
output_location = "3_analyse_data/bayes_output/logsize_density_tide/"
##### LODI #####
my_sp <- "LODI"
# Run models and save diagnostic plots
coda_list <- loop_coda_list(hexDF, species_abbrev = my_sp, my_model = my_model,
figs_location = output_location,
my_formula = ~ zx[,1] + zx[,2] + zx[,3])
