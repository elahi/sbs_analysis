X
summary(zm)
exp(summary(zm)$stat[1]) # size intercept (past)
summary(zm)$stat[2] # size intercept (past)
dat1 %>% group_by(era) %>% summarise(median(size1mm))
median_change(dat1)
median_change(dat2)
plot(zm)
gelman.diag(zm, multivariate = F)
mean(zj$pvalue.cv)
zj = jags.samples(jm, variable.names = c("beta", "sigma", "pvalue.cv"),
n.iter = n.iter, n.thin = 1)
mean(zj$pvalue.cv)
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.sim), col="red")
lines(density(zj$y.new), col="red")
zj = jags.samples(jm, variable.names = c("beta", "sigma", "pvalue.cv", "y.new"),
n.iter = n.iter, n.thin = 1)
mean(zj$pvalue.cv)
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.new), col="red")
head(zj)
head(zj$y.new)
dim(zj$y.new)
n.adapt = 3000
n.update = 3000
n.iter = 3000
inits = list(
list(
beta = as.vector(runif(n_betas, -1, 1)),
sigma = 1
),
list(
beta = as.vector(runif(n_betas, -1, 1)),
sigma = 1
)
)
## JAGS model
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
for (i in 1:n_betas){
beta[i] ~ dnorm(0, .00001)
}
sigma ~ dunif(0, 10)
tau <- 1/sigma^2
# likelihood
mu_mat <- X %*% beta # can't exponentiate a vector
for (i in 1:k){
mu[i] <- exp(mu_mat[i])
y[i] ~ dlnorm(log(mu[i]), tau)
y.new[i] ~ dlnorm(log(mu[i]), tau)
epsilon[i] <- y[i] - mu[i]
}
# derived quantities
cv.y <- sd(y[]) / mean(y[])
cv.y.new <- sd(y.new[]) / mean(y.new[])
pvalue.cv <- step(cv.y.new - cv.y)
}
", fill = TRUE)
sink()
start_time <- proc.time()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("beta", "sigma"),
n.iter = n.iter, n.thin = 1)
end_time <- proc.time()
end_time - start_time
#Produce a summary table for the parameters.
summary(zm)
exp(summary(zm)$stat[1]) # size intercept (past)
summary(zm)$stat[2] # size intercept (past)
# Compare with median values
dat1 %>% group_by(era) %>% summarise(median(size1mm))
median_change(dat1)
median_change(dat2)
#Produce trace plots of the chains for model parameters.
plot(zm)
# Test for convergence using the Gelman diagnostic.
gelman.diag(zm, multivariate = F)
zj = jags.samples(jm, variable.names = c("beta", "sigma", "pvalue.cv", "y.new"),
n.iter = n.iter, n.thin = 1)
# Check Bayesian pvals
mean(zj$pvalue.cv)
# Compared observed vs simulated
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.new), col="red")
head(zj$y.new)
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
for (i in 1:n_betas){
beta[i] ~ dnorm(0, .00001)
}
sigma ~ dunif(0, 10)
tau <- 1/sigma^2
# likelihood
mu_mat <- X %*% beta # can't exponentiate a vector
for (i in 1:k){
mu[i] <- exp(mu_mat[i])
y[i] ~ dlnorm(log(mu[i]), tau)
y.sim[i] ~ dlnorm(log(mu[i]), tau)
sq.error.data[i] <- (y[i] - y_mu[i])^2
sq.error.sim[i] <- (y.sim[i] - y_mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
start_time <- proc.time()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("beta", "sigma"),
n.iter = n.iter, n.thin = 1)
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
for (i in 1:n_betas){
beta[i] ~ dnorm(0, .00001)
}
sigma ~ dunif(0, 10)
tau <- 1/sigma^2
# likelihood
mu_mat <- X %*% beta # can't exponentiate a vector
for (i in 1:k){
mu[i] <- exp(mu_mat[i])
y[i] ~ dlnorm(log(mu[i]), tau)
y.sim[i] ~ dlnorm(log(mu[i]), tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.sim[i] <- (y.sim[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.sim <- sd(y.sim)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.sim)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
start_time <- proc.time()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("beta", "sigma"),
n.iter = n.iter, n.thin = 1)
zj = jags.samples(jm, variable.names = c("beta", "sigma", "y.sim", "p.mean", "p.sd", "p.discrep"),
n.iter = n.iter, n.thin = 1)
end_time <- proc.time()
end_time - start_time
mean(zj$p.mean)
mean(zj$p.sd)
mean(zj$p.discrep)
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.new), col="red")
lines(density(zj$y.sim), col="red")
summary(zm)
exp(summary(zm)$stat[1]) # size intercept (past)
summary(zm)$stat[2] # size intercept (past)
dat1 %>% group_by(era) %>% summarise(median(size1mm))
median_change(dat1)
median_change(dat2)
plot(zm)
gelman.diag(zm, multivariate = F)
mean(zj$p.mean)
mean(zj$p.sd)
mean(zj$p.discrep)
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.new), col="red")
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.new), col="red")
dat <- dat1
X <- model.matrix(~ eraJ, dat)
n_betas = ncol(X)
beta = as.vector(runif(n_betas, -1, 1))
beta
data = list(
y = as.double(dat$size1mm),
X = X,
k = as.double(length(dat$size1mm)),
#group = as.double(dat$group_j),
n_betas = as.double(n_betas),
thc = as.double(dat$thc),
era = as.double(dat$eraJ)
)
n_betas = ncol(X)
beta = as.vector(runif(n_betas, -1, 1))
beta
n.adapt = 1000
n.update = 1000
n.iter = 1000
inits = list(
list(
beta = as.vector(runif(n_betas, -1, 1)),
sigma = 1
),
list(
beta = as.vector(runif(n_betas, -1, 1)),
sigma = 1
)
)
sink("sbs_bayes/models/pooledJAGS_75.R")
cat("
model{
# priors
for (i in 1:n_betas){
beta[i] ~ dnorm(0, .00001)
}
sigma ~ dunif(0, 10)
tau <- 1/sigma^2
# likelihood
mu_mat <- X %*% beta # can't exponentiate a vector
for (i in 1:k){
mu[i] <- exp(mu_mat[i])
y[i] ~ dlnorm(log(mu[i]) - 0.67*sigma, tau)
y.new[i] ~ dlnorm(log(mu[i]) - 0.67*sigma, tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.sim[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.sim <- sd(y.new)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.new)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
start_time <- proc.time()
jm75 = jags.model("sbs_bayes/models/pooledJAGS_75.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm75, n.iter = n.update)
zm75 = coda.samples(jm75, variable.names = c("beta", "sigma"),
n.iter = n.iter, n.thin = 1)
zj75 = jags.samples(jm75, variable.names = c("beta", "sigma", "y.new", "p.mean", "p.sd", "p.discrep"),
n.iter = n.iter, n.thin = 1)
end_time <- proc.time()
end_time - start_time
summary(zm75)
exp(summary(zm75)$stat[1]) # size intercept (past)
summary(zm75)$stat[2] # size intercept (past)
dat1 %>% group_by(era) %>% summarise(median(size1mm))
median_change(dat1)
plot(zm75)
gelman.diag(zm75, multivariate = F)
mean(zj$p.mean)
mean(zj$p.sd)
mean(zj75$p.mean)
mean(zj75$p.sd)
mean(zj75$p.discrep)
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj75$y.new), col="red")
mean(zj75$p.mean)
mean(zj75$p.sd)
mean(zj75$p.discrep)
mean(zj$p.mean)
mean(zj$p.sd)
mean(zj$p.discrep)
mean(zj75$p.mean)
mean(zj75$p.sd)
mean(zj75$p.discrep)
zm75$stat
summary(zm75)$stat
summary(zm75)
str(summary(zm))
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.new), col="red")
lines(density(zj$y.sim), col="red")
lines(density(zj75$y.new), col="blue")
zj
zj75 = jags.samples(jm75, variable.names = c("beta", "sigma", "y.new", "p.mean", "p.sd", "p.discrep", "mu"),
n.iter = n.iter, n.thin = 1)
zj75$mu
crap <- zj75$mu
str(crap)
length(data$y)
View(X)
X
dat
pred_df <- dat %>% select(sp, site, era, size1mm)
pred_df
str(crap)
y_new <- zj75$y.new
y_new
y_new[1]
str(y_new)
y_new_df <- y_new[, , 1]
head(y_new_df)
pre_df <- cbind(pred_df, y_new_df)
pred_df <- dat %>% select(sp, site, era, size1mm)
pred_df <- cbind(pred_df, y_new_df)
lines(density(y_new_df))
source("sbs_bayes/00_sbs_bayes_data.R")
# Choose data - Chlorostoma
dat <- waraDF
unique(dat$site)
dat1 <- waraDF %>% filter(site == "Wara.B") %>% filter(!is.na(size1mm))
dat2 <- waraDF %>% filter(site == "Wara.D") %>% filter(!is.na(size1mm))
# load jags
library(rjags)
median_change <- function(dat){
dat_summary <- dat %>% group_by(era) %>%
summarise(size_median = median(size1mm, na.rm = TRUE))
test_stat <- 1 - (dat_summary$size_median[2]/dat_summary$size_median[1])
return(test_stat)
}
##### ERA - median #####
dat <- dat2
## Create model matrix
X <- model.matrix(~ eraJ, dat)
n_betas = ncol(X)
beta = as.vector(runif(n_betas, -1, 1))
beta
data = list(
y = as.double(dat$size1mm),
X = X,
k = as.double(length(dat$size1mm)),
n_betas = as.double(n_betas),
thc = as.double(dat$thc),
era = as.double(dat$eraJ)
)
n_betas = ncol(X)
beta = as.vector(runif(n_betas, -1, 1))
beta
n.adapt = 1000
n.update = 1000
n.iter = 1000
inits = list(
list(
beta = as.vector(runif(n_betas, -10, 10)),
sigma = 1)
# ),
# list(
#   beta = as.vector(runif(n_betas, -10, 10)),
#   sigma = 1
# )
)
inits
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
for (i in 1:n_betas){
beta[i] ~ dnorm(0, .00001)
}
sigma ~ dunif(0, 10)
tau <- 1/sigma^2
# likelihood
mu_mat <- X %*% beta # can't exponentiate a vector
for (i in 1:k){
mu[i] <- exp(mu_mat[i])
y[i] ~ dlnorm(log(mu[i]), tau)
y.new[i] ~ dlnorm(log(mu[i]), tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.sim[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.sim <- sd(y.new)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.new)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
start_time <- proc.time()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("beta", "sigma"),
n.iter = n.iter, n.thin = 1)
zj = jags.samples(jm, variable.names = c("beta", "sigma", "y.new", "p.mean", "p.sd", "p.discrep"),
n.iter = n.iter, n.thin = 1)
end_time <- proc.time()
end_time - start_time
summary(zm)
exp(summary(zm)$stat[1]) # size intercept (past)
summary(zm)$stat[2] # size intercept (past)
dat1 %>% group_by(era) %>% summarise(median(size1mm))
median_change(dat1)
median_change(dat2)
plot(zm)
mean(zj$p.mean)
mean(zj$p.sd)
mean(zj$p.discrep)
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.new), col="red")
dat <- waraDF
X <- model.matrix(~ eraJ, dat)
n_betas = ncol(X)
beta = as.vector(runif(n_betas, -1, 1))
beta
data = list(
y = as.double(dat$size1mm),
X = X,
k = as.double(length(dat$size1mm)),
n_betas = as.double(n_betas),
thc = as.double(dat$thc),
era = as.double(dat$eraJ)
)
n_betas = ncol(X)
beta = as.vector(runif(n_betas, -1, 1))
beta
n.adapt = 1000
n.update = 1000
n.iter = 1000
n.adapt = 2000
n.update = 2000
n.iter = 2000
inits = list(
list(
beta = as.vector(runif(n_betas, -10, 10)),
sigma = 1)
# ),
# list(
#   beta = as.vector(runif(n_betas, -10, 10)),
#   sigma = 1
# )
)
inits
sink("sbs_bayes/models/pooledJAGS.R")
cat("
model{
# priors
for (i in 1:n_betas){
beta[i] ~ dnorm(0, .00001)
}
sigma ~ dunif(0, 10)
tau <- 1/sigma^2
# likelihood
mu_mat <- X %*% beta # can't exponentiate a vector
for (i in 1:k){
mu[i] <- exp(mu_mat[i])
y[i] ~ dlnorm(log(mu[i]), tau)
y.new[i] ~ dlnorm(log(mu[i]), tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.sim[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.sim <- sd(y.new)
p.sd <- step(sd.sim - sd.data)
mean.data <- mean(y)
mean.sim  <- mean(y.new)
p.mean <- step(mean.sim - mean.data)
discrep.data <- sum(sq.error.data)
discrep.sim <- sum(sq.error.sim)
p.discrep <- step(discrep.sim - discrep.data)
}
", fill = TRUE)
sink()
start_time <- proc.time()
jm = jags.model("sbs_bayes/models/pooledJAGS.R", data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("beta", "sigma"),
n.iter = n.iter, n.thin = 1)
zj = jags.samples(jm, variable.names = c("beta", "sigma", "y.new", "p.mean", "p.sd", "p.discrep"),
n.iter = n.iter, n.thin = 1)
end_time <- proc.time()
end_time - start_time
#Produce a summary table for the parameters.
summary(zm)
exp(summary(zm)$stat[1]) # size intercept (past)
summary(zm)$stat[2]
dat1 %>% group_by(era) %>% summarise(median(size1mm))
median_change(dat)
dat %>% group_by(era) %>% summarise(median(size1mm))
waraDF %>% group_by(era) %>% summarise(median(size1mm))
dat %>% group_by(era) %>% summarise(median(size1mm))
dat <- waraDF %>% filter(!is.na(size1mm))
unique(dat$site)
dat %>% group_by(era) %>% summarise(median(size1mm))
summary(zm)
exp(summary(zm)$stat[1]) # size intercept (past)
summary(zm)$stat[2]
dat %>% group_by(era) %>% summarise(median(size1mm))
median_change(dat)
plot(zm)
gelman.diag(zm, multivariate = F)
mean(zj$p.mean)
mean(zj$p.sd)
mean(zj$p.discrep)
hist(data$y, breaks = 30, freq=FALSE) #note that this is the log transformed data
lines(density(zj$y.new), col="red")
end_time - start_time
