# Center and standardize
dens_mu <- mean(statDat$density_m2)
dens_sd <- sd(statDat$density_m2)
dens_cent <- statDat$density_m2 - dens_mu
statDat$dens_stand <- dens_cent/dens_sd
# For plotting predicted values
x_min <- min(statDat$density_m2)
x_max <- max(statDat$density_m2)
x_predict <- seq(x_min, x_max, length.out = 100)
x_predict_stand <- (x_predict - dens_mu)/dens_sd
# For prediction
era_predict <- c(0,1)
pred_df <- expand.grid(x_predict_stand, era_predict) %>%
rename(x_predict_stand = Var1, era_predict = Var2) %>% tbl_df()
pred_df$x_predict <- x_predict
# Get data
data = list(
N = nrow(statDat),
y = as.double(statDat$size1mm),
era = as.double(statDat$era01),
x = as.double(statDat$dens_stand),
x_predict = as.double(pred_df$x_predict_stand),
era_predict = as.double(pred_df$era_predict)
)
##### MODEL 1: ERA X SIZE ####
#' size ~ b0 + b1*era
# JAGS model
sink("3_analyse_data/bayes_models/modelJags.R")
cat("
model{
# priors
beta0 ~ dnorm(0, 1/10^2)
beta1 ~ dnorm(0, 1/10^2)
sigma ~ dunif(0, 5)
tau <- 1/sigma^2
# likelihood
for (i in 1:N){
mu[i] <- exp(beta0 + beta1*era[i])
y[i] ~ dlnorm(log(mu[i]), tau)
y.new[i] ~ dlnorm(log(mu[i]), tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.new[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.new <- sd(y.new)
p.sd <- step(sd.new - sd.data)
mean.data <- mean(y)
mean.new  <- mean(y.new)
p.mean <- step(mean.new - mean.data)
discrep.data <- sum(sq.error.data)
discrep.new <- sum(sq.error.new)
p.discrep <- step(discrep.new - discrep.data)
}
", fill = TRUE)
sink()
inits = list(
list(beta0 = 1, beta1 = 0.5, sigma = 1),
list(beta0 = 0.5, beta1 = -0.1, sigma = 4))
# Number of iterations
my_iterations <- 100
n.adapt <- my_iterations
n.update <- my_iterations
n.iter <- my_iterations
## Run model
jm <- jags.model("3_analyse_data/bayes_models/modelJags.R", data = data,
inits = inits, n.chains = length(inits),
n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("beta0", "beta1", "sigma"),
n.iter = n.iter, n.thin = 10)
zj = jags.samples(jm, variable.names = c("p.mean", "p.sd", "p.discrep"),
n.iter = n.iter, n.thin = 10)
#Produce a summary table for the parameters.
summary(zm)
exp(summary(zm)$stat[1]) # intercept
exp(2.55)
#Produce trace plots of the chains for model parameters.
plot(zm)
# Test for convergence using the Gelman diagnostic.
gelman.diag(zm, multivariate = F)
# Check Bayesian pvals
mean(zj$p.mean)
mean(zj$p.sd)
mean(zj$p.discrep)
# load jags
library(rjags)
## Iterations (5000 may not be enough for Wara)
n.adapt = 500
n.update = 500
n.iter = 500
# JAGS model
sink("3_analyse_data/bayes_models/modelJags.R")
cat("
model{
# priors
for(i in 1:p) {
b[i] ~ dnorm(0, 0.01)
}
sigma ~ dunif(0, 5)
tau <- 1/sigma^2
# likelihood
z <- X %*% b
for (i in 1:N){
mu[i] <- z[i]
y[i] ~ dnorm(mu[i], tau)
y.new[i] ~ dnorm(mu[i], tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.new[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.new <- sd(y.new)
p.sd <- step(sd.new - sd.data)
mean.data <- mean(y)
mean.new  <- mean(y.new)
p.mean <- step(mean.new - mean.data)
discrep.data <- sum(sq.error.data)
discrep.new <- sum(sq.error.new)
p.discrep <- step(discrep.new - discrep.data)
}
", fill = TRUE)
sink()
## Choose the model
my_model = "modelJags.R"
## My data
dat <- waraDF
dat <- dat %>% mutate(era01 = ifelse(era == "past", 0, 1))
## My species
my_species <- "Chlorostoma funebralis"
## My data type
my_data <- "individual size"
# Prepare data for JAGS
nData <- nrow(dat)
predictedName = "size_log"
predictorNames <- "era01"
zx <- get_jags_predictors(dat, predictorNames, standardize = F)
my_col_names <- colnames(zx)
get_jags_predictors
source("3_analyse_data/bayes_R/bayes_functions_general.R")
zx <- get_jags_predictors(dat, predictorNames, standardize = F)
my_col_names <- colnames(zx)
y <- as.matrix(dat[, predictedName])
x <- as.matrix(dat[, predictorNames])
# Get model matrix
my_formula = ~ zx[,1]
X <- model.matrix(my_formula)
p <- dim(X)[2]
# Data for JAGS
data = list(
X = X,
y = as.double(as.vector(y)),
N = nData,
p = p
)
# Get inits
inits <- list(
list(b = c(mean(log(y)), rep(0, p-1))),
list(b = c(0.2, rnorm(n = p-1, 0, 0.1))))
head(zx)
jm = jags.model(paste("3_analyse_data/bayes_models/", my_model, sep = ""),
data = data, inits = inits,
n.chains = length(inits), n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("b","sigma"),
n.iter = n.iter, n.thin = 1)
zj = jags.samples(jm, variable.names = c("b", "p.sd", "p.mean", "p.discrep"),
n.iter = n.iter, n.thin = 1)
#Produce a summary table for the parameters.
summary(zm)
b1_estimate <- summary(zm)$stat[1] # b1
b2_estimate <- summary(zm)$stat[2] # b2
10^b2_estimate
10^-b2_estimate
past_estimate <- (b1_estimate)
present_estimate <- (b1_estimate + b2_estimate)
(present_estimate - past_estimate)/past_estimate
#Produce trace plots of the chains for model parameters.
traceplot(zm)
densplot(zm)
# Test for convergence using the Gelman diagnostic.
gelman.diag(zm, multivariate = F)
# Inspect zj
str(zj$b)
# Check Bayesian pvals
pvals <- c(p.mean = mean(zj$p.mean), p.sd = mean(zj$p.sd), p.discrep = mean(zj$p.discrep))
pvals
# Get proportional change
zj_b0 <- zj$b[1,,]
head(zj_b0)
zj_b1 <- zj$b[2,,]
past_size <- 10^zj_b0
present_size <- 10^(zj_b0 + zj_b1)
prop_change <- (present_size - past_size)/past_size
prop_change_vec <- as.numeric(prop_change)
prop_change_quantile <- t(quantile(prop_change_vec, probs = c(0.025, 0.25, 0.5, 0.75, 0.975)))
rownames(prop_change_quantile) <- "prop_change"
# Save coda summary
coda_summary <- summary(zm)
coda_quantile <- data.frame(rbind(coda_summary$quantile, prop_change_quantile))
params <- rownames(coda_quantile)
coda_quantile <- coda_quantile %>%
mutate(species = my_species,
data = my_data,
param = params)
# Calculate on raw data
dat %>% group_by(era) %>%
summarise(mean = mean(size1mm)) %>%
spread(key = era, value = mean) %>%
mutate(prop_change = (present-past)/past)
coda_quantile
(present_estimate - past_estimate)/past_estimate
past_estimate
past_estimate <- 10^(b1_estimate)
present_estimate <- 10^(b1_estimate + b2_estimate)
(present_estimate - past_estimate)/past_estimate
10^b2_estimate
10^-b2_estimate
#Produce a summary table for the parameters.
summary(zm)
b1_estimate <- summary(zm)$stat[1] # b1
b2_estimate <- summary(zm)$stat[2] # b2
past_estimate
present_estimate
(present_estimate - past_estimate)/past_estimate
#Produce trace plots of the chains for model parameters.
traceplot(zm)
densplot(zm)
# Test for convergence using the Gelman diagnostic.
gelman.diag(zm, multivariate = F)
# Inspect zj
str(zj$b)
# Check Bayesian pvals
pvals <- c(p.mean = mean(zj$p.mean), p.sd = mean(zj$p.sd), p.discrep = mean(zj$p.discrep))
pvals
# Get proportional change
zj_b0 <- zj$b[1,,]
head(zj_b0)
zj_b1 <- zj$b[2,,]
past_size <- 10^zj_b0
present_size <- 10^(zj_b0 + zj_b1)
prop_change <- (present_size - past_size)/past_size
prop_change_vec <- as.numeric(prop_change)
prop_change_quantile <- t(quantile(prop_change_vec, probs = c(0.025, 0.25, 0.5, 0.75, 0.975)))
rownames(prop_change_quantile) <- "prop_change"
prop_change_quantile
# Save coda summary
coda_summary <- summary(zm)
coda_quantile <- data.frame(rbind(coda_summary$quantile, prop_change_quantile))
params <- rownames(coda_quantile)
coda_quantile <- coda_quantile %>%
mutate(species = my_species,
data = my_data,
param = params)
# Calculate on raw data
dat %>% group_by(era) %>%
summarise(mean = mean(size1mm)) %>%
spread(key = era, value = mean) %>%
mutate(prop_change = (present-past)/past)
coda_quantile
get_jags_predictors
##### PACKAGES, DATA #####
source("3_analyse_data/01_sbs_bayes_data.R")
statDat <- wara_means
summary(statDat)
# Get era as 0 or 1
statDat <- statDat %>% mutate(era01 = ifelse(era == "past", 0, 1))
# Center and standardize
dens_mu <- mean(statDat$density_m2)
dens_sd <- sd(statDat$density_m2)
dens_cent <- statDat$density_m2 - dens_mu
statDat$dens_stand <- dens_cent/dens_sd
statDat$tideHTm_stand <- as.numeric(scale(statDat$tideHTm))
# For plotting predicted values
x_min <- min(statDat$density_m2)
x_max <- max(statDat$density_m2)
x_predict <- seq(x_min, x_max, length.out = 100)
x_predict_stand <- (x_predict - dens_mu)/dens_sd
# For prediction
era_predict <- c(0,1)
pred_df <- expand.grid(x_predict_stand, era_predict) %>%
rename(x_predict_stand = Var1, era_predict = Var2) %>% tbl_df()
pred_df$x_predict <- x_predict
pred_df$tideHTm_stand <- 0
# Get data
data = list(
N = nrow(statDat),
y = as.double(statDat$size_log),
era = as.double(statDat$era01),
x = as.double(statDat$dens_stand),
tideHTm = as.double(statDat$tideHTm_stand),
x_predict = as.double(pred_df$x_predict_stand),
era_predict = as.double(pred_df$era_predict),
tide_predict = as.double(pred_df$tideHTm_stand)
)
statDat <- wara_means
summary(statDat)
# Get era as 0 or 1
statDat <- statDat %>% mutate(era01 = ifelse(era == "past", 0, 1))
# Standardize continuous variables
x2_mu <- mean(statDat$density_m2)
x2_sd <- sd(statDat$density_m2)
# Standardize continuous variables
x2_mu <- mean(statDat$density_m2)
x2_sd <- sd(statDat$density_m2)
x3_mu <- mean(statDat$tideHTm)
x3_sd <- sd(statDat$tideHTm)
# Get era as 0 or 1
statDat <- statDat %>% mutate(era01 = ifelse(era == "past", 0, 1))
# Get means and sd of continuous variables
x2_mu <- mean(statDat$density_m2)
x2_sd <- sd(statDat$density_m2)
x3_mu <- mean(statDat$tideHTm)
x3_sd <- sd(statDat$tideHTm)
# Standardize continuous variables
statDat$x2z <- as.numeric(scale(statDat$density_m2))
statDat$x3z <- as.numeric(scale(statDat$tideHTm))
predict_length <- 100
# For plotting predicted values
x2_min <- min(statDat$x2z)
x2_max <- max(statDat$x2z)
predict_length <- 100
x2z_pred <- seq(x_min, x_max, length.out = predict_length)
x2z_pred
# Standardize continuous variables
statDat$x2z <- as.numeric(scale(statDat$density_m2))
# For plotting predicted values
x2_min <- min(statDat$x2z)
x2_max <- max(statDat$x2z)
predict_length <- 100
x2z_pred <- seq(x_min, x_max, length.out = predict_length)
x2z_pred
statDat$x2z
x2z_pred <- seq(x2_min, x2_max, length.out = predict_length)
x2z_pred
make_predict_vector <- function(my_vector, predict_length = 100){
my_min <- min(my_vector)
my_max <- max(my_vector)
my_vector_pred <- seq(my_min, my_max, length.out = predict_length)
return(my_vector_pred)
}
x2z_pred <- make_predict_vector(statDat$density_m2, predict_length = 100)
x2z_pred
x2z_pred <- make_predict_vector(statDat$x2z, predict_length = 100)
x2z_pred
x3z_pred <- make_predict_vector(statDat$x3z, predict_length = 100)
x3z_pred
# For prediction
era_predict <- c(0,1)
# For prediction
era_predict <- c(0,1)
pred_df <- expand.grid(x2z_pred, era_predict) %>%
rename(x2z = Var1, x1 = Var2) %>% tbl_df()
pred_df
pred_df$x3z <- 0
# Get data
data = list(
N = nrow(statDat),
y = as.double(statDat$size_log),
x1 = as.double(statDat$era01),
x2 = as.double(statDat$x2z),
x3 = as.double(statDat$x3z),
x1_pred = as.double(pred_df$x1),
x2_pred = as.double(pred_df$x2z),
x3_pred = as.double(pred_df$x3z)
)
inits = list(
list(b0 = 1, rnorm(n=6, 0, 0.4), sigma = 3))
inits
inits = list(
list(c(b0 = 1, rnorm(n=6, 0, 0.4), sigma = 3)))
inits
# Number of iterations
n.adapt <- 1000
n.update <- 1000
n.iter <- 1000
# Get data
data = list(
N = nrow(statDat),
y = as.double(statDat$size_log),
x1 = as.double(statDat$era01),
x2 = as.double(statDat$x2z),
x3 = as.double(statDat$x3z),
x1_pred = as.double(pred_df$x1),
x2_pred = as.double(pred_df$x2z),
x3_pred = as.double(pred_df$x3z)
)
# JAGS model
sink("3_analyse_data/bayes_models/modelJags.R")
cat("
model{
# priors
b0 ~ dnorm(0, 1/10^2)
b1 ~ dnorm(0, 1/10^2)
b2 ~ dnorm(0, 1/10^2)
b3 ~ dnorm(0, 1/10^2)
b4 ~ dnorm(0, 1/10^2)
b5 ~ dnorm(0, 1/10^2)
b6 ~ dnorm(0, 1/10^2)
b7 ~ dnorm(0, 1/10^2)
sigma ~ dunif(0, 5)
tau <- 1/sigma^2
# likelihood
for (i in 1:N){
mu[i] <- b0 + b1*x1[i] + b2*x2[i] + b3*x3[i] + b4*x1[i]*x2[i] + b5*x1[i]*x3[i] + b6*x2[i]*x3[i] + b7*x1[i]*x2[i]*x3[i]
y[i] ~ dnorm(mu[i], tau)
y.new[i] ~ dnorm(mu[i], tau)
sq.error.data[i] <- (y[i] - mu[i])^2
sq.error.new[i] <- (y.new[i] - mu[i])^2
}
# bayesian p-values
sd.data <- sd(y)
sd.new <- sd(y.new)
p.sd <- step(sd.new - sd.data)
mean.data <- mean(y)
mean.new  <- mean(y.new)
p.mean <- step(mean.new - mean.data)
discrep.data <- sum(sq.error.data)
discrep.new <- sum(sq.error.new)
p.discrep <- step(discrep.new - discrep.data)
}
", fill = TRUE)
sink()
inits = list(
list(c(b0 = 1, rnorm(n=6, 0, 0.4), sigma = 3)))
inits
# Number of iterations
n.adapt <- 1000
n.update <- 1000
n.iter <- 1000
## Run model
jm <- jags.model("3_analyse_data/bayes_models/modelJags.R", data = data,
inits = inits, n.chains = length(inits),
n.adapt = n.adapt)
##### PREPARE DATA FOR JAGS #####
library(rjags)
## Run model
jm <- jags.model("3_analyse_data/bayes_models/modelJags.R", data = data,
inits = inits, n.chains = length(inits),
n.adapt = n.adapt)
inits = list(
list(b0 = 1, b1 = 0, b2 = 0, b3 = 0, b4 = 0, b5 = 0, b6 = 0, b7 = 0, sigma = 4))
# Number of iterations
n.adapt <- 1000
n.update <- 1000
n.iter <- 1000
## Run model
jm <- jags.model("3_analyse_data/bayes_models/modelJags.R", data = data,
inits = inits, n.chains = length(inits),
n.adapt = n.adapt)
update(jm, n.iter = n.update)
zm = coda.samples(jm, variable.names = c("b0",
"b1", "b2", "b3", "b4", "b5", "b6", "b7",
"sigma"),
n.iter = n.iter, n.thin = 10)
zj = jags.samples(jm, variable.names = c("p.mean", "p.sd", "p.discrep"),
n.iter = n.iter, n.thin = 10)
#Produce a summary table for the parameters.
summary(zm)
exp(summary(zm)$stat[1]) # intercept
#Produce trace plots of the chains for model parameters.
traceplot(zm)
densplot(zm)
# Test for convergence using the Gelman diagnostic.
gelman.diag(zm, multivariate = F)
# Check Bayesian pvals
mean(zj$p.mean)
mean(zj$p.sd)
mean(zj$p.discrep)
# Get proportional change
str(zj)
zj = jags.samples(jm, variable.names = c("b0", "b1","p.mean", "p.sd", "p.discrep"),
n.iter = n.iter, n.thin = 10)
# Get proportional change
str(zj)
zj_b0 <- zj$b0
head(zj_b0)
zj_b1 <- zj$b1
past_size <- 10^zj_b0
present_size <- 10^(zj_b0 + zj_b1)
prop_change <- (present_size - past_size)/past_size
prop_change_vec <- as.numeric(prop_change)
prop_change_quantile <- t(quantile(prop_change_vec, probs = c(0.025, 0.25, 0.5, 0.75, 0.975)))
rownames(prop_change_quantile) <- "prop_change"
# Save coda summary
coda_summary <- summary(zm)
coda_quantile <- data.frame(rbind(coda_summary$quantile, prop_change_quantile))
params <- rownames(coda_quantile)
coda_quantile <- coda_quantile %>%
mutate(species = my_species,
data = my_data,
param = params)
## My species
my_species <- "Chlorostoma funebralis"
## My data type
my_data <- "mean size"
coda_quantile <- coda_quantile %>%
mutate(species = my_species,
data = my_data,
param = params)
coda_quantile
##### SAVE OUTPUT #####
write.csv(x = coda_quantile, file = "3_analyse_data/bayes_output/by_species/chfu_logsize_means.csv")
# Save coda summary
coda_summary <- summary(zm)
coda_quantile <- data.frame(rbind(coda_summary$quantile, prop_change_quantile))
params <- rownames(coda_quantile)
coda_quantile <- coda_quantile %>%
mutate(species = my_species,
data = my_data,
param = params)
coda_quantile
